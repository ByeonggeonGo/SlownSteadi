{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import json \n",
    "import random\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498/498 [00:02<00:00, 242.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'내부 온도 1 평균': [14.4, 47.3],\n",
       " '내부 온도 1 최고': [14.5, 47.6],\n",
       " '내부 온도 1 최저': [14.4, 47.0],\n",
       " '내부 습도 1 평균': [34.1, 100.0],\n",
       " '내부 습도 1 최고': [36.5, 100.0],\n",
       " '내부 습도 1 최저': [32.4, 100.0],\n",
       " '내부 이슬점 평균': [12.4, 29.9],\n",
       " '내부 이슬점 최고': [12.8, 31.9],\n",
       " '내부 이슬점 최저': [12.1, 29.1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분석에 사용할 feature 선택\n",
    "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
    "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
    "\n",
    "# csv_files = sorted(glob('sample_data/*/*.csv'))\n",
    "csv_files = sorted(glob(path + '\\\\sample_data\\\\sample_data\\\\*\\\\*.csv'))\n",
    "\n",
    "temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
    "max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "\n",
    "# feature 별 최대값, 최솟값 계산\n",
    "for csv in tqdm(csv_files[1:]):\n",
    "    temp_csv = pd.read_csv(csv)[csv_features]\n",
    "    temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "    max_arr = np.max([max_arr,temp_max], axis=0)\n",
    "    min_arr = np.min([min_arr,temp_min], axis=0)\n",
    "\n",
    "# feature 별 최대값, 최솟값 dictionary 생성\n",
    "csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
    "csv_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 sample data는 파프리카와 시설포도 2종류의 작물만 존재\n",
    "label_description = {\n",
    " '3_00_0': '파프리카_정상',\n",
    " '3_a9_1': '파프리카흰가루병_초기',\n",
    " '3_a9_2': '파프리카흰가루병_중기',\n",
    " '3_a9_3': '파프리카흰가루병_말기',\n",
    " '3_a10_1': '파프리카잘록병_초기',\n",
    " '3_a10_2': '파프리카잘록병_중기',\n",
    " '3_a10_3': '파프리카잘록병_말기',\n",
    " '3_b3_1': '칼슘결핍_초기',\n",
    " '3_b3_2': '칼슘결핍_중기',\n",
    " '3_b3_3': '칼슘결핍_말기',\n",
    " '3_b6_1': '다량원소결핍 (N)_초기',\n",
    " '3_b6_2': '다량원소결핍 (N)_중기',\n",
    " '3_b6_3': '다량원소결핍 (N)_말기',\n",
    " '3_b7_1': '다량원소결핍 (P)_초기',\n",
    " '3_b7_2': '다량원소결핍 (P)_중기',\n",
    " '3_b7_3': '다량원소결핍 (P)_말기',\n",
    " '3_b8_1': '다량원소결핍 (K)_초기',\n",
    " '3_b8_2': '다량원소결핍 (K)_중기',\n",
    " '3_b8_3': '다량원소결핍 (K)_말기',\n",
    " '6_00_0': '시설포도_정상',\n",
    " '6_a11_1': '시설포도탄저병_초기',\n",
    " '6_a11_2': '시설포도탄저병_중기',\n",
    " '6_a11_3': '시설포도탄저병_말기',\n",
    " '6_a12_1': '시설포도노균병_초기',\n",
    " '6_a12_2': '시설포도노균병_중기',\n",
    " '6_a12_3': '시설포도노균병_말기',\n",
    " '6_b4_1': '일소피해_초기',\n",
    " '6_b4_2': '일소피해_중기',\n",
    " '6_b4_3': '일소피해_말기',\n",
    " '6_b5_1': '축과병_초기',\n",
    " '6_b5_2': '축과병_중기',\n",
    " '6_b5_3': '축과병_말기',\n",
    "}\n",
    "\n",
    "label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
    "label_decoder = {val:key for key, val in label_encoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataController():\n",
    "    def __init__(self,csvfeatures,csvfeaturedict):\n",
    "        self.csv_features = csvfeatures\n",
    "        self.csv_feature_dict = csvfeaturedict\n",
    "    \n",
    "    def road_csv(self,foldnam,timenum):\n",
    "        df = pd.read_csv(foldnam)\n",
    "        return df.loc[:timenum-1,self.csv_features]      #csv파일 제일 짧은게 291개임 오류인지는 모르겠으나 일단 최소길이로 통일하여 처리\n",
    "    \n",
    "    def scaling(self,minmaxdic,df):\n",
    "        for col in minmaxdic.keys():\n",
    "            df.loc[:,col] = df.loc[:,col] - csv_feature_dict[col][0]\n",
    "            df.loc[:,col] = df.loc[:,col] / (csv_feature_dict[col][1]-csv_feature_dict[col][0])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def getimage(self,imgpath):\n",
    "        img = cv2.imread(imgpath)\n",
    "        img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "        img = img.astype(np.float32)/223  ##픽셀값을 0~1사이로 정규화\n",
    "        # img = np.transpose(img, (2,0,1))\n",
    "        return img\n",
    "    \n",
    "    def getlable(self,jsonpath):\n",
    "        with open(jsonpath, 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "\n",
    "        crop = json_file['annotations']['crop']\n",
    "        disease = json_file['annotations']['disease']\n",
    "        risk = json_file['annotations']['risk']\n",
    "        label = f'{crop}_{disease}_{risk}'\n",
    "        return label\n",
    "    \n",
    "    def getdata(self,datapath,timenum,featnum):\n",
    "\n",
    "        csvarr = np.empty((0,timenum,featnum), float)\n",
    "        imgarr = np.empty((0,224,224,3), float)\n",
    "        lablearr = np.array([],dtype = int)\n",
    "        \n",
    "        # predictor = np.append(predictor,ndf.reshape(-1,timenum,featnum),axis = 0)\n",
    "        \n",
    "        for ind,i in enumerate(datapath):\n",
    "            \n",
    "            if glob(i + '/*.csv') == []:  #10462폴더 비어있음. 다음에 확인해보기\n",
    "                pass\n",
    "            else:\n",
    "                csvpath = glob(i + '/*.csv')[0]\n",
    "                imgpath = glob(i + '/*.jpg')[0]\n",
    "                jsonpath = glob(i + '/*.json')[0]\n",
    "                # con = DataController()\n",
    "                df = self.road_csv(csvpath,timenum)\n",
    "                df2 = self.scaling(csv_feature_dict,df).to_numpy().reshape(-1,timenum,featnum)\n",
    "                imgdata = self.getimage(imgpath).reshape(-1,224,224,3)\n",
    "                label = int(label_encoder[self.getlable(jsonpath)])\n",
    "                # label = self.getlable(jsonpath)\n",
    "                \n",
    "                \n",
    "                csvarr = np.append(csvarr,df2, axis = 0)\n",
    "                imgarr = np.append(imgarr,imgdata, axis = 0)\n",
    "                lablearr = np.append(lablearr,label)\n",
    "            \n",
    "        return [csvarr,imgarr],lablearr\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로젝트에 있는 모든 데이터폴터 불러오기\n",
    "data_files = glob(path + '\\\\sample_data\\\\sample_data\\\\*')\n",
    "#셔플\n",
    "random.shuffle(data_files)\n",
    "#앞에서 300번째까지 트레인셋으로\n",
    "trainfiles = data_files[:400]\n",
    "#나머지는 테스트셋으로\n",
    "testfiles = data_files[400:]\n",
    "\n",
    "# 데이터 컨트롤러\n",
    "dacon = DataController(csv_features,csv_feature_dict)\n",
    "# 배치화된 데이터셋 만들기\n",
    "# test셋용으로는 train = False로 하여 배치안생성하게됨\n",
    "x_train,y_train = dacon.getdata(trainfiles,260,9)\n",
    "x_test,y_test = dacon.getdata(testfiles,260,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprmodel(keras.Model):\n",
    "    def __init__(self, imgmodel,name = None):\n",
    "        super(preprmodel, self).__init__()\n",
    "        self.imgmodel = imgmodel\n",
    "        \n",
    "        self.block1_layer1 = tf.keras.layers.LSTM(128)\n",
    "        self.block1_layer2 = tf.keras.layers.Dense(64)\n",
    "        self.block1_layer3 = tf.keras.layers.Dense(32)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1 = self.imgmodel(inputs[1])\n",
    "\n",
    "        x2 = self.block1_layer1(inputs[0])\n",
    "        x2 = self.block1_layer2(x2)\n",
    "        x2 = self.block1_layer3(x2)\n",
    "    \n",
    "        x = tf.concat([x1,x2],axis=1)\n",
    "        return(x)\n",
    "\n",
    "model_RESNET50 = ResNet50(weights='imagenet')\n",
    "prepromodel = preprmodel(model_RESNET50)\n",
    "\n",
    "x_prime_train = prepromodel(x_train)\n",
    "x_prime_test = prepromodel(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 19, 20, 19, 19,  0,  0, 19, 19, 24,  1,  2, 19,  2,  0,  2, 19,\n",
       "        0,  0,  0, 19, 19, 19,  2, 19, 19,  0, 19,  1,  0,  0,  0,  3, 19,\n",
       "        0,  0,  0,  2, 26,  2, 19,  0, 19,  2, 19, 19, 24,  2,  1, 19,  1,\n",
       "        0,  2, 19, 19,  1, 19, 19, 19, 19,  1, 19, 19,  1,  0, 23,  0, 19,\n",
       "        1, 19,  0, 19,  0, 19, 19,  0,  0,  1, 19, 19, 19, 19,  0,  2,  2,\n",
       "        1,  3, 19, 19, 19,  2,  1,  0, 19,  0, 19,  0,  0, 19,  0,  0,  0,\n",
       "       19, 20,  0, 24, 24,  1, 19, 19, 19,  2,  0, 19, 19,  1, 24, 19,  0,\n",
       "       19,  0,  0, 19,  0, 19, 19,  0,  0, 19, 19,  6, 19,  0,  0, 19,  0,\n",
       "        1, 19,  0,  0,  1,  0,  0,  1, 19,  1, 19, 19,  0,  1,  0, 19, 19,\n",
       "       24,  0, 19, 19, 19,  0,  0,  2, 19,  0, 19, 19, 19, 26, 19,  0, 19,\n",
       "        0,  0, 19, 19,  0, 19,  0,  0,  6, 19, 19, 19, 19,  0, 29,  0,  0,\n",
       "       19, 19,  0, 19,  1,  0,  1,  0, 19, 19,  0,  0, 19,  1,  0, 24, 19,\n",
       "        0,  2,  0, 19, 19,  2,  0, 19,  0,  0, 19, 19,  3, 19, 21, 19, 19,\n",
       "       19,  0,  2,  4, 19,  1, 19, 19,  0,  0,  0,  0, 19,  0,  0,  1,  3,\n",
       "        1,  0,  2, 19,  0,  2,  2,  0, 19,  0, 19, 19,  0,  1, 19, 19, 19,\n",
       "        0, 19,  0, 19, 24, 19, 19,  1, 19,  0,  2,  1,  0,  2, 19, 19,  1,\n",
       "        2,  0,  0,  2, 19, 28,  0, 19,  0, 19, 19,  1, 19,  2,  0, 19, 20,\n",
       "       19,  0, 19,  0, 19, 19, 19,  0,  6,  2,  0, 19, 19, 19, 19,  1,  2,\n",
       "        0, 19,  0,  2, 19,  0,  0,  2,  0,  3,  1, 19,  0,  0,  0, 20, 24,\n",
       "        0, 19,  0,  1,  0, 19,  2,  0, 19,  0,  0, 19, 19, 19, 20,  0,  2,\n",
       "        0,  0,  0,  0,  0, 24,  0, 19, 19,  0, 19,  0, 19, 19,  1,  1, 19,\n",
       "        0,  0,  0,  1,  0, 19,  0,  5, 19, 19,  1,  0,  0,  0, 19,  2,  0,\n",
       "        0,  1,  0, 19, 19, 19,  0,  0, 19,  0,  0, 19, 28, 24, 19,  1, 19,\n",
       "        0, 19, 19,  0,  1,  0, 19,  3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  0   2   3   4   6   8   9  10  11  12  13  14  15  16  17  19  20  22\n",
      "  24  25  26  27  29  30  31  32  34  35  36  37  38  39  40  41  42  44\n",
      "  45  46  47  48  49  50  51  52  53  55  57  58  59  60  61  62  63  65\n",
      "  66  67  68  70  71  72  73  74  76  77  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  99 100 101 102 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 119 120 121 122 123 126 128 130 131\n",
      " 132 133 135 137 138 139 141 142 143 144 145 146 147 148 150 152 154 155\n",
      " 156 157 159 160 161 162 163 164 165 167 168 170 171 172 175 176 177 179\n",
      " 180 181 182 183 185 186 188 189 190 191 192 193 194 195 196 197 199 200\n",
      " 202 203 204 207 209 210 211 212 213 214 215 216 218 219 220 221 222 223\n",
      " 224 226 227 228 229 230 232 233 234 237 238 239 240 241 243 245 246 247\n",
      " 249 250 251 252 253 254 255 256 257 259 261 262 264 265 266 268 269 270\n",
      " 273 274 276 277 279 280 281 283 284 286 287 289 290 291 293 294 296 297\n",
      " 298 299 300 302 303 304 305 307 308 309 310 311 312 316 317 318 319 320\n",
      " 321 322 323 324 325 326 327 328 329 330 331 333 334 335 336 337 338 339\n",
      " 340 342 343 344 345 347 348 350 351 352 353 354 355 356 358 359 360 361\n",
      " 362 363 364 365 366 370 371 372 373 374 375 376 377 378 379 380 382 383\n",
      " 384 385 387 388 389 390 391 392 394 395 396 397 398] Val: [  1   5   7  18  21  23  28  33  43  54  56  64  69  75  78  96  97  98\n",
      " 103 118 124 125 127 129 134 136 140 149 151 153 158 166 169 173 174 178\n",
      " 184 187 198 201 205 206 208 217 225 231 235 236 242 244 248 258 260 263\n",
      " 267 271 272 275 278 282 285 288 292 295 301 306 313 314 315 332 341 346\n",
      " 349 357 367 368 369 381 386 393]\n",
      "TRAIN: [  0   1   2   4   5   7   8   9  11  12  13  14  16  17  18  21  22  23\n",
      "  24  25  28  29  30  32  33  34  36  37  38  40  42  43  44  48  49  51\n",
      "  52  53  54  55  56  57  58  61  62  63  64  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  81  82  83  85  86  87  89  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 105 106 107 108 109 111 112 113 114\n",
      " 115 116 117 118 119 122 123 124 125 126 127 129 130 131 134 135 136 137\n",
      " 138 139 140 141 143 144 145 146 148 149 151 153 154 155 156 158 159 162\n",
      " 164 165 166 167 168 169 170 172 173 174 175 176 177 178 179 180 181 182\n",
      " 183 184 185 186 187 189 192 193 194 196 198 200 201 202 203 205 206 207\n",
      " 208 210 211 212 214 215 216 217 218 220 221 222 223 224 225 226 227 228\n",
      " 230 231 232 235 236 237 238 239 240 242 243 244 245 246 248 250 251 252\n",
      " 253 255 256 257 258 259 260 261 262 263 264 266 267 268 269 270 271 272\n",
      " 273 274 275 276 277 278 280 281 282 283 284 285 286 287 288 289 290 292\n",
      " 294 295 296 297 298 299 301 302 303 305 306 307 308 309 311 312 313 314\n",
      " 315 316 317 319 321 323 324 325 326 327 328 329 330 331 332 333 334 336\n",
      " 337 338 340 341 342 343 344 345 346 348 349 350 351 353 354 355 356 357\n",
      " 358 359 361 363 364 365 366 367 368 369 370 371 372 373 374 377 378 380\n",
      " 381 383 384 386 387 388 389 390 391 393 395 396 397] Val: [  3   6  10  15  19  20  26  27  31  35  39  41  45  46  47  50  59  60\n",
      "  65  80  84  88  90 104 110 120 121 128 132 133 142 147 150 152 157 160\n",
      " 161 163 171 188 190 191 195 197 199 204 209 213 219 229 233 234 241 247\n",
      " 249 254 265 279 291 293 300 304 310 318 320 322 335 339 347 352 360 362\n",
      " 375 376 379 382 385 392 394 398]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18\n",
      "  19  20  21  23  24  26  27  28  30  31  33  34  35  36  38  39  41  43\n",
      "  44  45  46  47  49  50  53  54  56  57  58  59  60  63  64  65  66  67\n",
      "  68  69  70  72  73  74  75  76  77  78  79  80  82  84  86  88  89  90\n",
      "  91  92  93  94  95  96  97  98 100 102 103 104 105 106 107 109 110 113\n",
      " 114 116 118 119 120 121 122 124 125 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152 153 155\n",
      " 156 157 158 160 161 163 165 166 167 168 169 170 171 172 173 174 176 178\n",
      " 180 181 182 183 184 185 186 187 188 190 191 192 193 195 196 197 198 199\n",
      " 200 201 202 204 205 206 207 208 209 210 211 212 213 214 215 217 218 219\n",
      " 220 221 222 223 224 225 226 228 229 230 231 232 233 234 235 236 237 238\n",
      " 240 241 242 243 244 245 247 248 249 250 251 253 254 256 258 260 261 262\n",
      " 263 264 265 267 269 270 271 272 273 274 275 276 277 278 279 280 282 283\n",
      " 284 285 286 288 289 290 291 292 293 294 295 298 299 300 301 303 304 306\n",
      " 307 310 312 313 314 315 316 317 318 320 322 323 326 328 329 331 332 334\n",
      " 335 336 339 340 341 342 343 344 346 347 349 350 352 353 354 355 356 357\n",
      " 358 359 360 361 362 363 364 366 367 368 369 372 375 376 379 380 381 382\n",
      " 385 386 387 388 389 390 392 393 394 395 396 397 398] Val: [ 11  22  25  29  32  37  40  42  48  51  52  55  61  62  71  81  83  85\n",
      "  87  99 101 108 111 112 115 117 123 126 139 154 159 162 164 175 177 179\n",
      " 189 194 203 216 227 239 246 252 255 257 259 266 268 281 287 296 297 302\n",
      " 305 308 309 311 319 321 324 325 327 330 333 337 338 345 348 351 365 370\n",
      " 371 373 374 377 378 383 384 391]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8  10  11  13  14  15  17  18  19  20\n",
      "  21  22  23  25  26  27  28  29  30  31  32  33  35  36  37  39  40  41\n",
      "  42  43  45  46  47  48  49  50  51  52  53  54  55  56  58  59  60  61\n",
      "  62  63  64  65  66  68  69  70  71  72  75  78  79  80  81  83  84  85\n",
      "  86  87  88  90  91  93  96  97  98  99 100 101 103 104 105 106 108 110\n",
      " 111 112 115 117 118 120 121 123 124 125 126 127 128 129 131 132 133 134\n",
      " 135 136 137 139 140 141 142 143 147 149 150 151 152 153 154 155 157 158\n",
      " 159 160 161 162 163 164 166 167 169 171 172 173 174 175 176 177 178 179\n",
      " 180 181 183 184 185 187 188 189 190 191 192 193 194 195 197 198 199 201\n",
      " 202 203 204 205 206 207 208 209 211 212 213 215 216 217 219 225 226 227\n",
      " 228 229 231 233 234 235 236 238 239 240 241 242 244 245 246 247 248 249\n",
      " 251 252 254 255 257 258 259 260 261 263 265 266 267 268 270 271 272 273\n",
      " 274 275 278 279 280 281 282 283 285 287 288 290 291 292 293 294 295 296\n",
      " 297 299 300 301 302 303 304 305 306 308 309 310 311 312 313 314 315 316\n",
      " 317 318 319 320 321 322 323 324 325 327 329 330 331 332 333 334 335 336\n",
      " 337 338 339 341 342 343 345 346 347 348 349 350 351 352 354 355 357 359\n",
      " 360 362 363 364 365 367 368 369 370 371 373 374 375 376 377 378 379 381\n",
      " 382 383 384 385 386 390 391 392 393 394 396 397 398] Val: [  9  12  16  24  34  38  44  57  67  73  74  76  77  82  89  92  94  95\n",
      " 102 107 109 113 114 116 119 122 130 138 144 145 146 148 156 165 168 170\n",
      " 182 186 196 200 210 214 218 220 221 222 223 224 230 232 237 243 250 253\n",
      " 256 262 264 269 276 277 284 286 289 298 307 326 328 340 344 353 356 358\n",
      " 361 366 372 380 387 388 389 395]\n",
      "TRAIN: [  1   3   5   6   7   9  10  11  12  15  16  18  19  20  21  22  23  24\n",
      "  25  26  27  28  29  31  32  33  34  35  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  50  51  52  54  55  56  57  59  60  61  62  64  65  67\n",
      "  69  71  73  74  75  76  77  78  80  81  82  83  84  85  87  88  89  90\n",
      "  92  94  95  96  97  98  99 101 102 103 104 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 132\n",
      " 133 134 136 138 139 140 142 144 145 146 147 148 149 150 151 152 153 154\n",
      " 156 157 158 159 160 161 162 163 164 165 166 168 169 170 171 173 174 175\n",
      " 177 178 179 182 184 186 187 188 189 190 191 194 195 196 197 198 199 200\n",
      " 201 203 204 205 206 208 209 210 213 214 216 217 218 219 220 221 222 223\n",
      " 224 225 227 229 230 231 232 233 234 235 236 237 239 241 242 243 244 246\n",
      " 247 248 249 250 252 253 254 255 256 257 258 259 260 262 263 264 265 266\n",
      " 267 268 269 271 272 275 276 277 278 279 281 282 284 285 286 287 288 289\n",
      " 291 292 293 295 296 297 298 300 301 302 304 305 306 307 308 309 310 311\n",
      " 313 314 315 318 319 320 321 322 324 325 326 327 328 330 332 333 335 337\n",
      " 338 339 340 341 344 345 346 347 348 349 351 352 353 356 357 358 360 361\n",
      " 362 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383 384 385 386 387 388 389 391 392 393 394 395 398] Val: [  0   2   4   8  13  14  17  30  36  49  53  58  63  66  68  70  72  79\n",
      "  86  91  93 100 105 106 131 135 137 141 143 155 167 172 176 180 181 183\n",
      " 185 192 193 202 207 211 212 215 226 228 238 240 245 251 261 270 273 274\n",
      " 280 283 290 294 299 303 312 316 317 323 329 331 334 336 342 343 350 354\n",
      " 355 359 363 364 390 396 397]\n",
      "TRAIN: [  1   2   3   4   5   6   7   9  11  12  13  14  15  17  18  20  21  22\n",
      "  23  24  25  26  27  29  31  32  33  35  36  37  38  42  43  44  45  46\n",
      "  47  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  66\n",
      "  67  68  69  70  71  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  88  89  90  91  92  93  94  95  96  99 100 102 103 104 105 107 108 109\n",
      " 110 111 112 113 115 116 117 119 120 121 123 124 126 127 128 129 130 132\n",
      " 133 135 136 139 140 141 142 144 146 147 148 150 151 154 155 156 158 160\n",
      " 161 162 163 164 165 166 167 168 169 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 187 189 190 191 192 193 194 195 196 197 199 203 204\n",
      " 206 207 208 209 211 214 216 217 218 219 220 222 223 224 225 226 227 228\n",
      " 230 231 232 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248\n",
      " 249 250 251 252 253 254 257 258 259 260 261 262 263 264 265 266 268 269\n",
      " 270 271 272 273 274 275 276 278 279 280 281 282 283 284 285 286 287 288\n",
      " 290 291 292 293 295 296 297 298 300 301 302 305 306 307 308 309 310 312\n",
      " 313 314 316 318 319 321 322 323 325 327 328 329 331 333 334 335 337 338\n",
      " 341 343 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360\n",
      " 363 364 365 366 367 368 369 370 371 372 374 378 379 380 381 382 383 384\n",
      " 385 386 387 388 390 391 392 393 394 395 396 397 398] Val: [  0   8  10  16  19  28  30  34  39  40  41  48  65  72  73  87  97  98\n",
      " 101 106 114 118 122 125 131 134 137 138 143 145 149 152 153 157 159 170\n",
      " 185 186 188 198 200 201 202 205 210 212 213 215 221 229 233 255 256 267\n",
      " 277 289 294 299 303 304 311 315 317 320 324 326 330 332 336 339 340 342\n",
      " 344 361 362 373 375 376 377 389]\n",
      "TRAIN: [  0   1   3   4   5   6   7   8   9  10  11  14  15  16  19  20  23  26\n",
      "  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  52  53  55  57  58  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  73  75  76  77  78  79  82  83  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 104\n",
      " 105 106 111 112 113 114 115 116 118 120 122 123 124 125 127 128 129 130\n",
      " 131 134 135 136 137 138 139 140 141 142 143 144 145 147 148 149 150 151\n",
      " 152 153 154 155 157 159 161 162 163 165 166 167 168 169 170 172 174 176\n",
      " 177 179 180 181 182 183 185 186 187 188 190 192 193 194 196 198 199 200\n",
      " 201 202 203 205 208 209 210 211 212 213 215 217 218 220 221 223 224 225\n",
      " 226 227 229 230 231 232 233 236 237 238 239 240 241 243 245 246 247 248\n",
      " 249 251 253 254 255 256 257 258 260 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 276 277 278 280 281 282 283 284 285 286 287 288 289\n",
      " 292 293 294 295 297 298 299 300 301 302 303 304 305 306 307 309 311 312\n",
      " 313 314 315 316 317 319 320 322 324 325 326 327 329 330 332 333 334 335\n",
      " 336 337 338 339 340 341 342 343 344 346 347 349 351 352 354 355 356 357\n",
      " 359 360 361 362 365 367 368 370 371 372 373 374 375 376 377 380 382 383\n",
      " 384 385 386 387 388 389 390 391 392 394 396 397 398] Val: [  2  12  13  17  18  21  22  24  25  54  56  74  80  81 103 107 108 109\n",
      " 110 117 119 121 126 132 133 146 156 158 160 164 171 173 175 178 184 189\n",
      " 191 195 197 204 206 207 214 216 219 222 228 234 235 242 244 250 252 259\n",
      " 261 279 290 291 296 308 310 318 321 323 328 331 345 348 350 353 358 363\n",
      " 364 366 369 378 379 381 393 395]\n",
      "TRAIN: [  0   1   2   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  32  33  34  36  37  39\n",
      "  40  41  43  45  47  48  50  51  53  54  55  56  57  58  62  63  65  70\n",
      "  72  73  74  75  76  77  78  79  80  81  82  84  86  87  88  89  90  91\n",
      "  92  93  94  96  97  98 101 103 106 107 108 109 110 111 112 113 114 115\n",
      " 117 118 119 120 121 122 123 125 126 127 128 130 131 132 133 134 135 136\n",
      " 137 138 139 140 142 143 144 145 146 149 150 151 152 153 154 155 156 157\n",
      " 158 159 160 162 164 166 167 169 170 171 172 173 174 175 176 177 178 180\n",
      " 181 182 183 184 185 186 187 188 189 191 194 195 197 198 199 200 201 202\n",
      " 204 205 206 207 208 210 211 212 213 214 215 216 219 221 222 223 227 228\n",
      " 229 230 231 232 233 234 235 236 237 238 240 241 242 244 245 246 250 251\n",
      " 252 253 255 256 257 259 260 261 263 265 266 267 270 271 272 274 275 276\n",
      " 277 279 280 281 282 284 285 286 287 289 290 291 292 293 294 295 296 297\n",
      " 299 300 302 303 304 305 307 308 310 311 312 314 315 316 317 318 319 320\n",
      " 321 323 324 325 326 328 330 331 332 333 334 336 337 338 339 340 341 342\n",
      " 343 344 345 347 348 350 351 352 353 354 355 356 358 360 361 362 363 364\n",
      " 365 366 367 368 369 371 373 374 375 376 377 378 379 381 382 383 384 385\n",
      " 386 387 388 389 390 391 392 393 394 395 396 397 398] Val: [  3  31  35  38  42  44  46  49  52  59  60  61  64  66  67  68  69  71\n",
      "  83  85  95  99 100 102 104 105 116 124 129 141 147 148 161 163 165 168\n",
      " 179 190 192 193 196 203 209 217 218 220 224 225 226 239 243 247 248 249\n",
      " 254 258 262 264 268 269 273 278 283 288 298 301 306 309 313 322 327 329\n",
      " 335 346 349 357 359 370 372 380]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8  10  12  13  14  16  17  18  19  20\n",
      "  21  22  23  24  25  27  28  30  31  32  34  35  37  38  39  40  41  42\n",
      "  43  44  46  47  48  49  50  51  52  54  56  59  60  61  62  64  65  66\n",
      "  67  68  69  71  72  73  74  76  80  81  82  83  84  85  86  87  89  90\n",
      "  91  92  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 113 114 116 117 118 119 120 121 122 124 125 126 128 129 131 132 133 134\n",
      " 135 137 138 139 141 143 145 146 147 148 149 152 153 156 157 158 159 160\n",
      " 161 163 164 165 166 167 168 170 171 173 175 176 177 178 179 180 184 185\n",
      " 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203\n",
      " 204 205 206 207 208 209 210 212 213 214 215 216 217 218 219 220 221 222\n",
      " 223 224 225 226 228 229 230 233 234 235 238 239 241 242 243 244 245 247\n",
      " 248 249 250 251 252 254 255 256 257 258 259 261 262 263 264 266 267 268\n",
      " 269 270 273 274 275 277 278 279 282 283 284 285 288 289 290 291 293 294\n",
      " 296 297 298 299 300 301 303 304 305 306 308 309 310 311 312 313 314 315\n",
      " 317 318 319 320 321 322 323 324 326 327 328 329 330 331 332 333 335 336\n",
      " 338 339 340 341 342 343 344 345 346 348 349 350 352 353 354 355 357 358\n",
      " 359 360 361 362 363 364 365 366 367 369 370 372 373 375 376 377 378 379\n",
      " 380 381 383 384 385 387 388 389 391 392 393 395 398] Val: [  9  11  15  26  29  33  36  45  53  55  57  58  63  70  75  77  78  79\n",
      "  88  93  94 111 112 115 123 127 130 136 140 142 144 150 151 154 155 162\n",
      " 169 172 174 181 182 183 211 227 231 232 236 237 240 246 253 260 265 271\n",
      " 272 276 280 281 286 287 292 295 302 307 316 325 334 337 347 351 356 368\n",
      " 371 374 382 386 390 394 396 397]\n",
      "TRAIN: [  0   2   3   8   9  10  11  12  13  15  16  17  18  19  21  22  24  25\n",
      "  26  28  29  30  31  33  34  35  36  38  39  40  41  42  44  45  46  48\n",
      "  49  52  53  54  55  56  57  58  59  60  61  63  64  65  66  67  68  69\n",
      "  70  71  72  73  74  75  77  78  79  80  81  83  85  87  88  93  94  95\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 114 115\n",
      " 116 117 118 119 121 122 123 124 125 126 127 129 130 131 132 133 134 136\n",
      " 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155\n",
      " 156 157 158 159 160 161 162 163 164 165 168 169 170 171 172 173 174 175\n",
      " 178 179 181 182 183 184 185 186 188 189 190 191 192 193 195 196 197 198\n",
      " 200 201 202 203 204 205 206 207 209 210 211 212 213 214 215 216 217 218\n",
      " 219 220 221 222 224 225 226 227 228 229 231 232 233 234 235 236 237 239\n",
      " 240 242 243 244 246 247 248 249 250 252 253 254 255 256 258 259 260 261\n",
      " 262 264 265 267 268 269 271 272 273 276 277 278 279 280 281 283 286 287\n",
      " 288 289 290 291 292 294 295 296 298 299 301 302 303 304 306 307 308 309\n",
      " 310 311 313 315 316 317 318 320 321 322 323 324 325 326 327 328 329 330\n",
      " 331 332 334 335 336 337 339 340 342 344 345 346 347 348 349 350 351 353\n",
      " 356 357 358 359 361 362 363 364 366 368 369 370 371 372 373 374 375 376\n",
      " 377 378 379 380 381 382 386 389 390 393 394 395 396 397] Val: [  1   4   5   6   7  14  20  23  27  32  37  43  47  50  51  62  76  82\n",
      "  84  86  89  90  91  92  96 113 120 128 135 139 166 167 176 177 180 187\n",
      " 194 199 208 223 230 238 241 245 251 257 263 266 270 274 275 282 284 285\n",
      " 293 297 300 305 312 314 319 333 338 341 343 352 354 355 360 365 367 383\n",
      " 384 385 387 388 391 392 398]\n",
      "TRAIN: [  0   1   3   4   6   7   8  10  11  14  15  16  17  21  22  23  24  25\n",
      "  26  27  28  29  30  32  33  34  35  36  38  39  40  41  42  44  45  46\n",
      "  47  48  50  51  52  55  56  57  58  60  61  62  63  64  65  66  68  69\n",
      "  71  72  73  74  75  77  79  81  82  83  84  85  86  87  88  89  94  95\n",
      "  96  97  98  99 100 101 103 105 106 107 108 109 111 113 114 117 119 120\n",
      " 121 122 123 124 125 126 128 130 131 132 133 134 136 137 138 139 144 145\n",
      " 146 147 148 149 153 155 156 159 160 161 162 163 164 165 166 167 168 170\n",
      " 171 172 173 175 176 177 178 179 180 181 182 183 184 185 186 188 189 190\n",
      " 191 192 193 194 195 196 197 198 199 200 202 203 204 205 207 208 209 210\n",
      " 211 212 213 214 215 216 218 219 220 221 222 223 224 225 226 227 229 230\n",
      " 231 232 233 234 235 236 238 239 240 241 242 243 244 245 246 247 249 251\n",
      " 252 253 254 255 257 258 259 260 261 263 264 265 266 267 269 270 271 272\n",
      " 274 275 276 277 278 279 280 281 283 284 285 286 288 289 290 291 293 294\n",
      " 295 296 297 298 299 302 303 304 306 307 309 310 313 314 315 316 317 318\n",
      " 319 320 321 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337\n",
      " 339 340 341 342 344 345 346 347 348 349 350 351 353 354 355 356 357 358\n",
      " 360 361 362 363 365 366 367 369 370 371 373 375 376 377 379 381 382 383\n",
      " 384 385 386 387 388 390 391 392 394 395 396 397 398] Val: [  2   5   9  12  13  18  19  20  31  37  43  49  53  54  59  67  70  76\n",
      "  78  80  90  91  92  93 102 104 110 112 115 116 118 127 129 135 140 141\n",
      " 142 143 150 151 152 154 157 158 169 174 187 201 206 217 228 237 248 250\n",
      " 256 262 268 273 282 287 292 300 301 305 308 311 312 322 338 343 352 359\n",
      " 364 368 372 374 378 380 389 393]\n",
      "TRAIN: [  0   1   2   3   4   5   6   8   9  10  12  13  14  15  17  18  19  20\n",
      "  21  22  23  24  27  28  29  31  32  33  34  35  36  37  38  39  40  41\n",
      "  42  43  44  45  46  49  50  51  52  53  54  56  57  58  59  60  61  62\n",
      "  64  65  67  68  69  70  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  98 100 101 102 104\n",
      " 105 107 110 111 112 113 115 116 117 118 119 120 121 122 125 126 127 128\n",
      " 129 130 131 133 135 136 140 141 142 143 144 145 146 147 148 149 150 151\n",
      " 152 153 154 155 156 157 158 159 161 162 163 164 165 166 167 168 169 171\n",
      " 174 175 177 179 180 182 183 184 185 186 187 189 192 194 195 196 197 198\n",
      " 201 202 203 204 205 206 207 208 209 211 212 213 214 215 217 218 219 220\n",
      " 221 222 224 226 227 228 231 232 233 235 236 237 238 239 240 242 244 245\n",
      " 246 247 248 250 252 253 254 255 256 258 259 260 261 262 263 264 265 267\n",
      " 268 269 270 271 272 273 275 276 277 278 279 280 281 282 283 285 286 287\n",
      " 288 289 290 292 293 294 296 297 299 300 301 302 303 304 305 306 307 308\n",
      " 309 310 311 312 313 315 316 317 318 320 321 322 323 324 325 326 327 329\n",
      " 331 332 335 336 337 338 339 341 343 345 347 349 350 352 355 359 360 362\n",
      " 363 364 365 366 367 368 369 371 372 374 375 377 378 379 380 381 382 383\n",
      " 384 385 386 387 389 390 391 392 393 394 396 397 398] Val: [  7  11  16  25  26  30  47  48  55  63  66  71  97  99 103 106 108 109\n",
      " 114 123 124 132 134 137 138 139 160 170 172 173 176 178 181 188 190 191\n",
      " 193 199 200 210 216 223 225 229 230 234 241 243 249 251 257 266 274 284\n",
      " 291 295 298 314 319 328 330 333 334 340 342 344 346 348 351 353 354 356\n",
      " 357 358 361 370 373 376 388 395]\n",
      "TRAIN: [  0   1   2   5   6   7   9  10  11  12  13  16  18  19  20  21  23  25\n",
      "  26  27  29  30  31  32  33  34  35  37  39  41  42  43  46  47  48  49\n",
      "  52  53  54  55  56  58  59  60  61  62  63  64  65  66  67  68  70  71\n",
      "  72  73  75  76  77  78  79  80  81  85  86  88  89  90  91  92  93  96\n",
      "  97  98  99 100 102 103 104 105 106 107 108 109 110 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 127 129 132 133 134 135 136 137 138\n",
      " 139 140 141 142 143 144 147 148 149 150 151 152 153 154 157 158 159 160\n",
      " 161 162 163 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 186 187 188 189 190 191 192 193 195 196 197 199 200 201 203\n",
      " 204 206 209 210 212 214 215 216 217 218 219 220 221 222 223 224 225 226\n",
      " 227 228 229 230 231 232 234 235 237 238 239 240 241 242 243 244 245 247\n",
      " 248 249 250 251 252 253 254 255 256 257 258 260 262 263 264 265 266 268\n",
      " 270 271 272 273 274 276 277 278 279 280 281 282 283 284 287 288 289 290\n",
      " 291 292 293 294 295 296 298 299 300 301 303 305 308 309 310 311 312 313\n",
      " 314 315 317 318 319 320 322 323 324 326 328 329 330 332 333 334 335 337\n",
      " 338 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 356 357\n",
      " 358 359 360 361 362 363 364 366 367 368 370 371 372 373 374 375 376 377\n",
      " 378 380 383 386 388 389 390 391 392 393 395 396 398] Val: [  3   4   8  14  15  17  22  24  28  36  38  40  44  45  50  51  57  69\n",
      "  74  82  83  84  87  94  95 101 111 126 128 130 131 145 146 155 156 164\n",
      " 183 184 185 194 198 202 205 207 208 211 213 233 236 246 259 261 267 269\n",
      " 275 285 286 297 302 304 306 307 316 321 325 327 331 336 339 355 365 369\n",
      " 379 381 382 384 385 387 394 397]\n",
      "TRAIN: [  0   2   3   4   5   7   8   9  11  12  13  14  15  16  17  18  19  20\n",
      "  21  22  23  24  25  26  28  29  30  31  33  34  36  37  38  39  40  41\n",
      "  42  43  44  45  47  48  49  50  51  52  53  54  55  57  58  59  63  66\n",
      "  67  69  70  71  72  74  75  76  78  79  80  82  83  84  86  87  89  90\n",
      "  91  92  93  94  95  96  97  99 101 102 103 104 105 106 108 109 110 111\n",
      " 112 113 114 115 116 117 118 123 124 126 127 128 129 130 131 132 134 135\n",
      " 137 138 139 140 141 142 143 145 146 148 150 151 152 153 154 155 156 157\n",
      " 158 159 160 162 164 169 170 171 172 173 174 175 176 177 178 179 181 182\n",
      " 183 184 185 187 188 190 191 192 193 194 195 197 198 199 200 201 202 204\n",
      " 205 206 207 208 209 210 211 212 213 214 216 217 218 221 222 223 225 226\n",
      " 227 228 229 230 231 233 234 235 236 237 238 240 241 243 244 246 247 248\n",
      " 249 250 251 253 255 256 257 259 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 276 278 279 281 282 284 285 286 287 290 291 292 293\n",
      " 294 295 297 298 300 301 302 304 305 306 307 308 310 311 312 313 314 315\n",
      " 316 319 321 322 323 324 325 326 327 328 330 331 332 333 334 335 336 338\n",
      " 339 340 342 343 344 346 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 361 362 363 364 365 367 368 369 370 372 373 374 375 376 378 379 380 381\n",
      " 382 383 384 385 387 388 389 391 393 394 395 396 397] Val: [  1   6  10  27  32  35  46  56  60  61  62  64  65  68  73  77  81  85\n",
      "  88  98 100 107 119 120 121 122 125 133 136 144 147 149 161 163 165 166\n",
      " 167 168 180 186 189 196 203 215 219 220 224 232 239 242 245 252 254 258\n",
      " 260 277 280 283 288 289 296 299 303 309 317 318 320 329 337 341 345 347\n",
      " 360 366 371 377 386 390 392 398]\n",
      "TRAIN: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  22  24  25  26  27  28  30  31  32  35  36  37  38  40  43  44\n",
      "  45  46  47  48  49  50  51  53  54  55  56  57  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  73  74  76  77  78  80  81  82  83  84  85\n",
      "  87  88  90  91  92  93  94  95  97  98  99 100 101 102 103 104 106 107\n",
      " 108 109 110 111 112 114 115 116 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 149 150 151 152 154 155 156 157 158 160 161 163 164 165 166 167\n",
      " 168 169 170 172 173 174 176 178 180 181 183 184 185 186 187 188 189 190\n",
      " 191 193 194 196 198 199 200 201 202 203 205 206 207 208 210 211 213 215\n",
      " 216 217 219 220 223 224 225 228 229 230 232 233 234 236 237 239 241 242\n",
      " 243 245 246 248 249 250 251 252 254 256 257 258 259 260 261 262 266 267\n",
      " 268 269 273 274 275 277 280 282 283 284 285 286 287 288 289 291 292 295\n",
      " 296 297 298 299 300 301 302 303 304 305 306 307 308 309 311 312 314 316\n",
      " 317 318 319 320 321 322 325 327 328 329 330 331 333 334 336 337 338 339\n",
      " 340 341 342 343 344 345 346 347 348 351 352 353 354 355 356 357 358 359\n",
      " 360 361 364 365 366 368 369 370 371 372 373 374 376 377 378 379 380 381\n",
      " 382 384 385 386 387 388 389 390 392 393 394 395 397 398] Val: [  0  21  23  29  33  34  39  41  42  52  58  72  75  79  86  89  96 105\n",
      " 113 117 148 153 159 162 171 175 177 179 182 192 195 197 204 209 212 214\n",
      " 218 221 222 226 227 231 235 238 240 244 247 253 255 263 264 265 270 271\n",
      " 272 276 278 279 281 290 293 294 310 313 315 323 324 326 332 335 349 350\n",
      " 362 363 367 375 383 391 396]\n",
      "TRAIN: [  0   1   2   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19\n",
      "  21  22  23  24  25  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  50  51  52  55  57  58  59  60  62  63\n",
      "  64  66  67  68  69  70  72  74  76  77  78  79  80  81  82  83  84  86\n",
      "  87  88  89  90  91  92  93  95  96  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 112 114 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 131 133 134 135 136 137 139 140 142 143 144 145 146 148 150 151\n",
      " 154 155 156 157 159 160 162 163 165 166 167 169 170 171 172 175 176 177\n",
      " 178 179 181 182 184 186 187 189 190 191 195 196 197 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 217 220 221 222 224 226\n",
      " 227 228 229 230 231 233 234 236 237 238 239 241 242 243 244 245 246 247\n",
      " 248 249 250 251 252 253 254 255 256 257 259 260 263 265 266 267 268 270\n",
      " 272 273 274 275 276 278 280 281 282 283 284 285 287 289 290 291 292 293\n",
      " 294 295 297 299 300 301 302 303 304 306 307 309 310 311 312 313 314 315\n",
      " 316 317 318 320 321 322 323 324 325 326 328 329 330 331 332 333 334 337\n",
      " 338 339 340 341 342 343 345 346 347 348 349 350 351 352 353 354 355 356\n",
      " 358 359 360 362 363 364 365 368 369 370 371 372 373 374 375 376 377 379\n",
      " 380 381 382 383 384 385 386 387 388 389 390 391 395] Val: [  3   4  20  26  27  49  53  54  56  61  65  71  73  75  85  94 111 113\n",
      " 115 116 130 132 138 141 147 149 152 153 158 161 164 168 173 174 180 183\n",
      " 185 188 192 193 194 198 199 218 219 223 225 232 235 240 258 261 262 264\n",
      " 269 271 277 279 286 288 296 298 305 308 319 327 335 336 344 357 361 366\n",
      " 367 378 392 393 394 396 397 398]\n",
      "TRAIN: [  0   1   3   4   5   6   7   8   9  10  13  14  15  16  18  19  20  21\n",
      "  22  24  25  26  27  29  32  33  35  36  37  38  40  41  42  43  44  45\n",
      "  46  47  49  50  51  53  54  56  58  61  62  63  64  65  67  69  70  71\n",
      "  72  73  75  76  77  78  79  80  81  82  84  85  86  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 102 103 104 105 106 107 108 110 111 112\n",
      " 113 114 115 116 117 118 119 121 122 123 124 130 131 132 133 134 136 137\n",
      " 138 139 140 141 142 144 146 147 148 149 150 152 153 154 155 156 157 158\n",
      " 160 161 162 163 164 165 166 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 182 183 184 185 186 187 188 189 190 192 193 194 195 196 198 199\n",
      " 200 202 205 206 207 208 209 210 212 214 216 217 218 219 220 221 222 223\n",
      " 224 225 227 231 232 233 234 235 236 237 239 240 242 243 244 245 246 247\n",
      " 248 249 253 254 255 256 258 259 260 261 262 263 264 265 267 268 269 270\n",
      " 271 273 274 275 276 277 279 281 282 283 284 286 287 288 289 290 291 292\n",
      " 294 295 296 297 298 300 302 303 304 305 306 307 308 309 312 313 315 316\n",
      " 317 318 319 320 321 322 323 324 325 326 327 328 329 331 334 335 336 338\n",
      " 339 340 342 344 345 346 347 349 352 353 354 355 356 357 358 359 360 361\n",
      " 362 363 364 365 366 367 368 369 370 371 372 373 374 375 377 378 380 381\n",
      " 384 385 386 388 389 390 392 393 394 395 396 397 398] Val: [  2  11  12  17  23  28  30  31  34  39  48  52  55  57  59  60  66  68\n",
      "  74  83  87 101 109 120 125 126 127 128 129 135 143 145 151 159 167 181\n",
      " 191 197 201 203 204 211 213 215 226 228 229 230 238 241 250 251 252 257\n",
      " 266 272 278 280 285 293 299 301 310 311 314 330 332 333 337 341 343 348\n",
      " 350 351 376 379 382 383 387 391]\n",
      "TRAIN: [  1   2   3   4   5   6   7   8  10  11  12  14  15  17  18  19  20  21\n",
      "  23  24  25  26  27  28  30  31  32  33  34  35  36  37  39  41  42  43\n",
      "  44  45  47  48  49  52  53  54  55  56  57  58  59  60  61  63  64  65\n",
      "  66  67  68  70  71  72  73  74  75  77  78  80  81  83  84  85  87  88\n",
      "  90  91  92  94  95  96  97  98  99 100 101 102 104 105 106 108 109 110\n",
      " 111 112 113 114 115 116 120 122 125 126 127 128 129 130 131 132 133 135\n",
      " 136 138 140 141 142 143 144 145 147 148 149 150 151 152 153 154 156 157\n",
      " 158 159 160 161 163 164 165 166 167 168 170 171 173 174 176 177 178 179\n",
      " 180 181 183 184 185 187 188 190 191 192 193 194 195 196 197 198 199 200\n",
      " 201 202 203 204 205 206 207 209 210 211 212 213 215 217 218 219 220 222\n",
      " 223 224 225 226 227 228 229 230 231 232 234 235 236 238 239 240 241 242\n",
      " 244 247 249 250 251 252 255 256 257 258 259 261 262 263 264 265 266 269\n",
      " 270 271 272 273 274 276 277 278 279 280 281 283 285 286 287 288 290 291\n",
      " 292 293 295 296 298 299 300 301 302 303 305 306 307 308 309 310 311 312\n",
      " 313 314 315 316 317 318 319 320 321 322 323 324 325 327 328 329 330 331\n",
      " 332 333 334 335 336 337 338 339 340 341 343 344 345 346 348 349 350 351\n",
      " 355 357 358 360 361 362 366 367 369 370 371 373 375 376 377 378 379 382\n",
      " 383 384 385 386 387 391 392 393 394 395 396 397 398] Val: [  0   9  13  16  22  29  38  40  46  50  51  62  69  76  79  82  86  89\n",
      "  93 103 107 117 118 119 121 123 124 134 137 139 146 155 162 169 172 175\n",
      " 182 186 189 208 214 216 221 233 237 243 245 246 248 253 254 260 267 268\n",
      " 275 282 284 289 294 297 304 326 342 347 352 353 354 356 359 363 364 365\n",
      " 368 372 374 380 381 388 389 390]\n",
      "TRAIN: [  0   1   2   3   4   6   8   9  10  11  12  13  14  15  16  17  19  20\n",
      "  22  23  24  25  26  27  28  29  30  31  34  35  37  38  39  40  42  44\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  65\n",
      "  66  68  69  71  73  74  75  76  77  79  81  82  83  84  85  86  87  89\n",
      "  91  92  93  94  98 100 101 102 103 105 106 107 109 110 111 113 114 115\n",
      " 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133\n",
      " 134 135 136 137 138 139 140 141 143 145 146 147 148 149 150 151 152 153\n",
      " 155 156 158 159 161 162 163 164 165 167 168 169 171 172 173 174 175 176\n",
      " 177 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195\n",
      " 197 198 199 201 203 204 208 209 211 213 214 215 216 218 219 221 222 223\n",
      " 225 226 227 228 229 230 232 233 235 236 237 238 240 241 243 245 246 248\n",
      " 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 266 267 268\n",
      " 269 270 271 272 274 275 276 277 278 279 280 282 283 284 285 286 288 289\n",
      " 290 293 294 296 297 298 299 301 302 304 305 306 307 308 310 311 312 314\n",
      " 315 316 317 319 320 321 322 323 326 327 330 332 333 334 335 336 337 338\n",
      " 340 341 342 343 344 345 347 348 350 351 352 353 354 356 357 359 360 361\n",
      " 363 364 365 366 367 368 369 372 373 374 375 376 378 379 380 381 382 383\n",
      " 386 387 388 389 390 391 392 393 394 395 396 397 398] Val: [  5   7  18  21  32  33  36  41  43  45  63  64  67  70  72  78  80  88\n",
      "  90  95  96  97  99 104 108 112 142 144 154 157 160 166 170 178 196 200\n",
      " 202 205 206 207 210 212 217 220 224 231 234 239 242 244 247 249 265 273\n",
      " 281 287 291 292 295 300 303 309 313 318 324 325 328 329 331 339 346 349\n",
      " 355 358 362 370 371 377 384 385]\n",
      "TRAIN: [  0   2   3   4   5   7   9  11  12  13  16  17  18  20  21  22  23  26\n",
      "  27  28  29  30  31  32  33  34  36  38  39  40  41  43  45  46  48  49\n",
      "  50  51  52  53  54  55  56  57  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  78  79  80  82  83  85  86  87  88  89\n",
      "  90  93  94  95  96  97  99 101 103 104 107 108 109 111 112 113 115 116\n",
      " 117 118 119 120 121 123 124 125 126 127 128 129 130 132 134 135 137 138\n",
      " 139 141 142 143 144 145 146 147 149 151 152 153 154 155 157 158 159 160\n",
      " 161 162 164 166 167 168 169 170 172 173 174 175 178 180 181 182 183 185\n",
      " 186 188 189 191 192 193 194 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 210 211 212 213 214 215 216 217 218 219 220 221 223 224 225 226\n",
      " 228 229 230 231 232 233 234 235 237 238 239 240 241 242 243 244 245 246\n",
      " 247 248 249 250 251 252 253 254 257 258 260 261 262 264 265 266 267 268\n",
      " 269 271 272 273 275 277 278 279 280 281 282 284 285 286 287 288 289 291\n",
      " 292 293 294 295 296 297 298 299 300 301 303 304 305 308 309 310 311 313\n",
      " 314 318 319 324 325 326 327 328 329 330 331 332 333 335 336 337 339 341\n",
      " 342 343 344 346 347 348 349 350 351 352 353 354 355 356 357 358 359 361\n",
      " 362 363 364 365 366 367 368 370 371 372 374 376 377 378 379 380 381 382\n",
      " 383 384 385 387 388 389 390 391 392 393 394 396 397 398] Val: [  1   6   8  10  14  15  19  24  25  35  37  42  44  47  58  77  81  84\n",
      "  91  92  98 100 102 105 106 110 114 122 131 133 136 140 148 150 156 163\n",
      " 165 171 176 177 179 184 187 190 195 209 222 227 236 255 256 259 263 270\n",
      " 274 276 283 290 302 306 307 312 315 316 317 320 321 322 323 334 338 340\n",
      " 345 360 369 373 375 386 395]\n",
      "TRAIN: [  1   2   3   4   5   6   8   9  10  11  12  13  14  15  16  17  19  21\n",
      "  22  24  25  26  28  30  31  32  33  38  39  40  41  42  43  44  45  46\n",
      "  48  49  51  52  53  54  55  56  57  58  59  61  62  64  65  66  67  68\n",
      "  70  71  73  74  76  77  78  79  80  81  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 105 107 108 109 110\n",
      " 111 112 113 114 116 117 118 119 120 123 124 125 126 129 130 131 132 134\n",
      " 136 137 138 139 140 141 143 145 147 149 150 151 153 154 155 156 158 159\n",
      " 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 177 179\n",
      " 180 183 184 185 186 187 188 189 190 191 192 193 194 195 196 198 201 202\n",
      " 203 204 205 206 207 208 210 211 212 213 215 216 217 219 221 223 224 225\n",
      " 226 227 228 229 230 232 233 235 237 239 240 241 242 243 244 245 246 247\n",
      " 248 249 250 251 252 253 254 255 256 257 258 260 262 263 264 265 267 268\n",
      " 269 270 271 273 274 275 276 278 279 280 281 282 283 284 285 286 288 289\n",
      " 290 292 293 294 295 296 297 298 299 300 301 302 303 304 306 307 309 310\n",
      " 311 312 314 315 316 318 320 322 323 324 325 327 329 330 332 334 335 336\n",
      " 337 338 340 341 342 343 345 347 348 350 351 352 354 355 356 357 358 359\n",
      " 360 362 363 364 366 367 368 369 370 371 372 373 374 375 377 378 379 380\n",
      " 381 382 383 384 387 388 389 390 392 395 396 397 398] Val: [  0   7  18  20  23  27  29  34  35  36  37  47  50  60  63  69  72  75\n",
      "  82 104 106 115 121 122 127 128 133 135 142 144 146 148 152 157 176 178\n",
      " 181 182 197 199 200 209 214 218 220 222 231 234 236 238 259 261 266 272\n",
      " 277 287 291 305 308 313 317 319 321 326 328 331 333 339 344 346 349 353\n",
      " 361 365 376 385 386 391 393 394]\n",
      "TRAIN: [  0   1   2   4   5   6   7   8   9  10  12  13  14  18  19  20  21  22\n",
      "  23  26  27  28  29  31  32  33  34  35  36  37  39  40  41  42  43  44\n",
      "  46  47  48  49  50  51  52  53  54  57  58  59  60  62  63  64  65  66\n",
      "  67  68  69  70  71  72  73  74  75  77  79  80  81  82  85  86  87  88\n",
      "  89  90  92  93  94  95  96  97  98 101 102 103 104 105 106 108 109 110\n",
      " 111 113 115 116 117 118 120 121 122 124 125 126 127 128 129 130 131 132\n",
      " 133 135 136 137 138 139 141 142 143 144 145 146 148 149 150 151 152 153\n",
      " 154 156 157 158 159 160 162 163 165 167 168 169 170 171 172 173 175 176\n",
      " 177 178 179 180 181 182 183 184 185 186 187 188 191 192 193 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206 207 208 209 211 212 213 214 215\n",
      " 216 217 218 219 220 222 223 226 227 228 230 231 232 233 234 235 236 237\n",
      " 238 240 241 242 243 244 248 249 250 251 252 253 254 255 256 257 258 259\n",
      " 261 262 264 265 266 268 269 270 272 274 275 276 277 278 279 280 281 282\n",
      " 283 285 286 287 290 291 293 294 295 297 298 299 300 301 303 304 305 306\n",
      " 307 308 310 311 312 313 314 315 316 317 318 319 320 321 324 325 326 327\n",
      " 328 329 330 331 333 334 336 337 338 339 340 342 344 345 346 347 348 349\n",
      " 350 352 353 355 356 360 361 362 363 365 367 368 369 371 372 375 376 377\n",
      " 378 382 383 385 386 387 389 391 392 393 394 396 398] Val: [  3  11  15  16  17  24  25  30  38  45  55  56  61  76  78  83  84  91\n",
      "  99 100 107 112 114 119 123 134 140 147 155 161 164 166 174 189 190 210\n",
      " 221 224 225 229 239 245 246 247 260 263 267 271 273 284 288 289 292 296\n",
      " 302 309 322 323 332 335 341 343 351 354 357 358 359 364 366 370 373 374\n",
      " 379 380 381 384 388 390 395 397]\n",
      "TRAIN: [  0   1   3   4   5   6   7   8   9  10  11  12  15  16  17  18  19  20\n",
      "  21  22  23  24  25  26  27  29  30  31  32  34  35  36  37  38  41  42\n",
      "  43  44  45  47  48  49  50  51  53  55  56  60  61  63  64  66  68  69\n",
      "  70  72  73  75  76  77  78  82  83  84  85  86  87  88  89  90  91  92\n",
      "  96  97  99 100 102 103 104 105 106 107 108 109 111 112 113 114 115 116\n",
      " 117 118 119 121 122 123 127 128 129 130 131 133 134 135 137 138 140 141\n",
      " 142 143 144 145 146 147 148 150 151 152 153 155 157 158 159 161 162 163\n",
      " 164 165 166 167 168 170 171 172 174 175 176 177 178 179 180 181 182 185\n",
      " 186 188 189 190 192 193 194 195 196 197 198 199 200 201 202 204 205 206\n",
      " 208 209 210 211 212 213 214 216 218 220 221 222 223 224 225 226 227 228\n",
      " 229 230 231 232 233 234 235 236 237 238 239 240 241 242 245 246 247 250\n",
      " 251 252 253 256 258 259 260 261 262 263 264 265 266 267 268 270 271 272\n",
      " 273 274 277 280 281 282 283 284 285 286 287 288 289 290 291 292 293 296\n",
      " 298 300 301 302 303 304 305 306 307 308 309 310 311 313 315 316 317 318\n",
      " 319 320 321 322 323 326 327 328 329 331 332 333 335 336 337 338 339 340\n",
      " 341 343 344 346 348 349 351 352 353 354 355 356 357 358 359 360 361 362\n",
      " 363 364 365 366 368 369 370 372 373 374 375 376 377 379 380 381 382 384\n",
      " 385 386 387 388 389 390 391 393 394 395 396 397 398] Val: [  2  13  14  28  33  39  40  46  52  54  57  58  59  62  65  67  71  74\n",
      "  79  80  81  93  94  95  98 101 110 120 124 125 126 132 136 139 149 154\n",
      " 156 160 169 173 183 184 187 191 203 207 215 217 219 243 244 248 249 254\n",
      " 255 257 269 275 276 278 279 294 295 297 299 312 314 324 325 330 334 342\n",
      " 345 347 350 367 371 378 383 392]\n",
      "TRAIN: [  0   2   3   5   7   9  10  11  12  13  14  15  16  17  18  20  21  23\n",
      "  24  25  27  28  29  30  33  34  35  36  37  38  39  40  45  46  47  48\n",
      "  49  50  52  53  54  55  56  57  58  59  60  61  62  63  64  65  67  69\n",
      "  71  72  74  75  76  77  78  79  80  81  82  83  84  85  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 104 106 107 109 110 111 112 113\n",
      " 114 115 116 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 142 143 144 146 147 148 149 150 152 153\n",
      " 154 155 156 157 159 160 161 162 164 166 167 168 169 170 173 174 175 176\n",
      " 178 179 181 182 183 184 187 188 189 190 191 192 193 197 199 200 203 204\n",
      " 207 208 209 210 214 215 216 217 218 219 220 221 222 223 224 225 227 228\n",
      " 229 231 232 233 234 235 236 238 239 240 241 243 244 245 246 247 248 249\n",
      " 250 251 253 254 255 256 257 258 259 260 261 262 263 264 266 267 269 271\n",
      " 272 273 275 276 277 278 279 280 281 284 285 287 288 289 290 291 292 294\n",
      " 295 296 297 299 300 301 302 303 305 306 307 308 309 310 312 313 314 315\n",
      " 317 319 321 322 323 324 325 326 328 330 331 332 333 334 335 338 339 341\n",
      " 342 343 344 345 346 347 348 349 350 351 353 354 357 358 359 360 361 362\n",
      " 364 365 366 367 368 369 370 371 373 374 376 378 379 380 381 382 383 384\n",
      " 385 386 387 388 389 390 391 392 393 394 395 397 398] Val: [  1   4   6   8  19  22  26  31  32  41  42  43  44  51  66  68  70  73\n",
      "  86  87  88 103 105 108 117 141 145 151 158 163 165 171 172 177 180 185\n",
      " 186 194 195 196 198 201 202 205 206 211 212 213 226 230 237 242 252 265\n",
      " 268 270 274 282 283 286 293 298 304 311 316 318 320 327 329 336 337 340\n",
      " 352 355 356 363 372 375 377 396]\n",
      "TRAIN: [  0   1   2   3   4   6   7   8  11  13  14  15  16  17  18  19  20  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  50  51  52  54  55  56  57  58  59  60  61\n",
      "  62  63  65  66  67  68  69  70  71  72  73  74  75  76  78  79  80  81\n",
      "  82  83  84  86  87  88  91  93  94  95  98  99 100 101 103 104 105 106\n",
      " 107 108 110 112 114 115 117 119 120 121 122 123 124 125 126 127 128 132\n",
      " 133 134 135 136 139 140 141 142 144 145 146 147 148 149 151 152 154 155\n",
      " 156 157 158 160 161 163 164 165 166 169 171 172 173 174 176 177 178 180\n",
      " 181 182 183 184 185 186 187 189 190 191 194 195 196 197 198 199 200 201\n",
      " 202 203 205 206 207 209 210 211 212 213 214 215 217 218 219 220 221 222\n",
      " 224 225 226 229 230 231 234 236 237 238 239 242 243 244 245 246 247 248\n",
      " 249 252 254 255 257 259 260 261 263 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 282 283 284 286 287 288 289 291 292 293 294 295\n",
      " 296 297 298 299 302 304 305 308 309 311 312 313 314 316 317 318 319 320\n",
      " 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 339\n",
      " 340 341 342 343 344 345 346 347 349 350 351 352 353 354 355 356 357 358\n",
      " 359 361 363 364 365 366 367 370 371 372 373 374 375 376 377 378 379 380\n",
      " 381 383 384 385 386 388 390 391 392 393 394 395 396 397] Val: [  5   9  10  12  21  48  49  53  64  77  85  89  90  92  96  97 102 109\n",
      " 111 113 116 118 129 130 131 137 138 143 150 153 159 162 167 168 170 175\n",
      " 179 188 192 193 204 208 216 223 227 228 232 233 235 240 241 250 251 253\n",
      " 256 258 262 264 280 281 285 290 300 301 303 306 307 310 315 338 348 360\n",
      " 362 368 369 382 387 389 398]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhqud\\AppData\\Local\\Temp/ipykernel_14828/3722576918.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Train_set_X = np.array(Train_set_X)\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Temp/ipykernel_14828/3722576918.py:82: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Train_set_y = np.array(Train_set_y)\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Temp/ipykernel_14828/3722576918.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Val_set_X = np.array(Val_set_X)\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Temp/ipykernel_14828/3722576918.py:84: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  Val_set_y = np.array(Val_set_y)\n"
     ]
    }
   ],
   "source": [
    "# **최적화파트**\n",
    "import pickle\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval, STATUS_OK\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "# # f1_score(y_true, y_pred, average=[‘micro’, ‘macro’, ‘samples’,’weighted’ 중 하나 선택])\n",
    "# f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "###서치공간\n",
    "space_xgb = [hp.uniform('learn',0.01,0.8),            #학습률\n",
    "         hp.quniform('nesti',100,350,q=10),          #\n",
    "         hp.quniform('maxd',3,8,q=1),                #\n",
    "         hp.quniform('minc',  1,10,q=1),             #과적합을 방지할 목적으로사용한다. 기본값은 1이지만 너무 높은값은 오히려 과소적합을 일으키기 때문에 적절한 값을 찾아야함 \n",
    "         hp.uniform('gamm',  0.1,3),              #\n",
    "         hp.uniform('subsa',  0.5,1),\n",
    "         hp.uniform('colsample_b',  0.6,0.9),\n",
    "         #hp.quniform('scalepos',  0.8,1.2,q=0.1)\n",
    "         #hp.quniform('times',  0,6,q=1)\n",
    "         ]\n",
    "\n",
    "\n",
    "###함수\n",
    "def XGB(args):\n",
    "    learn,nesti,maxd,minc,gamm,subsa,colsample_b = args\n",
    "    nesti,maxd,minc=int(nesti),int(maxd),int(minc)#,int(times)\n",
    "    xgb=XGBClassifier(\n",
    "        learning_rate =learn,\n",
    "        n_estimators=nesti,\n",
    "        max_depth=maxd,\n",
    "        min_child_weight=minc,\n",
    "        gamma=gamm,\n",
    "        subsample=subsa,\n",
    "        colsample_bytree=colsample_b,\n",
    "        # scale_pos_weight=scalepos,\n",
    "        #seed=seed_value,\n",
    "        use_label_encoder=False,\n",
    "        n_jobs = -1,\n",
    "        seed = 100,\n",
    "        # num_class=32,\n",
    "        )\n",
    "    \n",
    "    for t in range(len(Train_set_X)):\n",
    "        x_train, y_train = Train_set_X[t], Train_set_y[t]\n",
    "        x_val, y_val = Val_set_X[t], Val_set_y[t]\n",
    "        xgb.fit(x_train, y_train.ravel()) #validation_data=(x_val, y_val))\n",
    "        y_pred=xgb.predict(x_val)\n",
    "        y_pred=y_pred.reshape((len(y_pred),1),)\n",
    "\n",
    "\n",
    "        result = -f1_score(y_val, y_pred, average='macro')\n",
    "        resultdf.loc[t,['result']]=result\n",
    "        \n",
    "        del x_train, y_train\n",
    "        del x_val, y_val\n",
    "    #print(resultdf['auc'])\n",
    "    result = resultdf['result'].mean()\n",
    "    return(result)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=5,random_state = 100)\n",
    "# kf = StratifiedKFold()\n",
    "Train_set_X = []\n",
    "Train_set_y = []\n",
    "Val_set_X = []\n",
    "Val_set_y = []\n",
    "#\n",
    "x_prime_train = np.array(x_prime_train)\n",
    "x_prime_test = np.array(x_prime_test)\n",
    "\n",
    "#\n",
    "for train_index, val_index in kf.split(x_prime_train,y_train):\n",
    "    print(\"TRAIN:\", train_index, \"Val:\", val_index)\n",
    "    X_tra, X_val = x_prime_train[train_index,:], x_prime_train[val_index,:]\n",
    "    y_tra, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    Train_set_X.append(X_tra)\n",
    "    Train_set_y.append(y_tra)\n",
    "    Val_set_X.append(X_val)\n",
    "    Val_set_y.append(y_val)\n",
    "\n",
    "Train_set_X = np.array(Train_set_X)\n",
    "Train_set_y = np.array(Train_set_y)\n",
    "Val_set_X = np.array(Val_set_X)\n",
    "Val_set_y = np.array(Val_set_y)\n",
    "#\n",
    "result = {\"result\":[np.nan]}\n",
    "resultdf = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 20, 19, 19,  0, 19, 24,  1,  2, 19,  2,  0,  2, 19,  0,  0, 19,\n",
       "       19, 19, 19,  0, 19,  0,  0,  0,  3,  0,  0,  0,  2, 26,  2, 19,  0,\n",
       "       19, 19, 19, 24,  2,  1, 19,  1,  0,  2, 19,  1, 19, 19, 19,  1, 19,\n",
       "       19,  1, 23,  0, 19,  1,  0, 19,  0, 19, 19,  0,  1, 19, 19, 19,  0,\n",
       "        2,  2,  1,  3, 19, 19, 19,  2,  1,  0, 19,  0, 19,  0,  0,  0, 19,\n",
       "        0, 24, 24,  1, 19, 19, 19,  2,  0, 19, 19,  1, 24, 19, 19,  0,  0,\n",
       "       19,  0,  0, 19,  6, 19,  0,  0,  0, 19,  0,  0,  0,  0,  1, 19,  1,\n",
       "       19, 19,  0,  0, 19,  0, 19, 19, 19,  0,  2, 19,  0, 19, 19, 19, 19,\n",
       "        0,  0,  0, 19, 19,  0,  0, 19, 19, 19, 19,  0,  0,  0, 19,  0, 19,\n",
       "        1,  0,  1,  0, 19, 19,  0, 19,  1, 24, 19,  0, 19,  2,  0, 19,  0,\n",
       "        0, 19, 19,  3, 21, 19, 19, 19,  0,  2,  4,  1, 19, 19,  0,  0,  0,\n",
       "       19,  0,  3,  1,  0,  2, 19,  2,  0, 19,  0, 19,  0,  1, 19, 19, 19,\n",
       "        0, 19,  0, 24, 19,  1,  0,  2,  1,  2, 19, 19,  0,  0, 19, 28, 19,\n",
       "        0, 19,  1, 19,  0, 19, 19,  0, 19, 19, 19,  0,  6,  2,  0, 19, 19,\n",
       "       19,  1,  2, 19,  0,  2, 19,  0,  0,  1, 19,  0,  0,  0, 20, 24,  0,\n",
       "       19,  0,  1,  0, 19,  2,  0, 19,  0, 19, 19, 19, 20,  0,  2,  0,  0,\n",
       "        0,  0, 24, 19, 19, 19,  0, 19, 19,  1,  1, 19,  0,  0,  1,  0, 19,\n",
       "        0,  5, 19, 19,  0, 19,  2,  0,  0,  1,  0, 19, 19, 19,  0, 19,  0,\n",
       "        0, 19, 24, 19,  1, 19,  0, 19,  0,  1,  0, 19,  3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_set_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [3:40:08<00:00, 132.09s/trial, best loss: -0.4927369749001771]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trials=Trials()\n",
    "#trials = pickle.load(open(path+site+'0929_suffle_onlystep4_KfoldCV+accuracy+weightx_t+0_nomalx_ECx- 2019x.p', \"rb\"))    #trials불러오기\n",
    "starttime = time.time()\n",
    "#if optype == \"tpe\":\n",
    "best = fmin(XGB,space_xgb,algo=tpe.suggest,max_evals=100,trials=trials)\n",
    "optime = time.time() - starttime\n",
    "#else:\n",
    "#  best = fmin(XGB,space_xgb,algo=rand.suggest,max_evals=10,trials=trials,rstate= np.random.RandomState(seed_value))\n",
    "\n",
    "pickle.dump(trials, open(path+\"\\\\models\"+\"\\\\xgb_histoy_%s.p\" %(time.strftime('%Y%m%d_%H', time.localtime(starttime))), \"wb\"))     #trials저장하기\n",
    "#print(best)\n",
    "#print(space_eval(space_xgb, best))\n",
    "\n",
    "###테스트셋에 테스트\n",
    "###테스트셋에 테스트\n",
    "learn=best['learn']\n",
    "nesti=int(best['nesti'])\n",
    "maxd=int(best['maxd'])\n",
    "minc=int(best['minc'])\n",
    "gamm=best['gamm']\n",
    "subsa=best['subsa']\n",
    "colsample_b=best['colsample_b']\n",
    "learn=best['learn']\n",
    "# scalepos=best['scalepos']\n",
    "\n",
    "#\n",
    "'''\n",
    "learn=0.0107605633620193\n",
    "nesti=int(100)\n",
    "maxd=int(5)\n",
    "minc=int(2)\n",
    "gamm=22.5170863426934\n",
    "subsa=0.315853538049625\n",
    "colsample_b=0.801462768751276\n",
    "scalepos=int(9)\n",
    "'''\n",
    "######최적화모델성능\n",
    "xgb=XGBClassifier(\n",
    "        learning_rate =learn,\n",
    "        n_estimators=nesti,\n",
    "        max_depth=maxd,\n",
    "        min_child_weight=minc,\n",
    "        gamma=gamm,\n",
    "        subsample=subsa,\n",
    "        colsample_bytree=colsample_b,\n",
    "        nthread=-1,\n",
    "        use_label_encoder=False,\n",
    "        # scale_pos_weight=scalepos,\n",
    "        n_jobs = -1,\n",
    "        seed=100,\n",
    "        # num_class=32,\n",
    "        )\n",
    "\n",
    "\n",
    "xgb.fit(x_prime_train, y_train)#,eval_set=eval_set)\n",
    "#최종점수#\n",
    "y_pred=xgb.predict(x_prime_test)\n",
    "from sklearn import metrics\n",
    "#결과\n",
    "matricresult = metrics.classification_report(y_test, y_pred, digits=3)\n",
    "pickle.dump(xgb, open(path+\"\\\\models\"+\"\\\\xgb_model_%s.p\" %(time.strftime('%Y%m%d_%H', time.localtime(starttime))), \"wb\"))\n",
    "pickle.dump(matricresult, open(path+\"\\\\models\"+\"\\\\xgb_matrix_%s.p\" %(time.strftime('%Y%m%d_%H', time.localtime(starttime))), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>시설포도_정상</th>\n",
       "      <th>시설포도노균병_중기</th>\n",
       "      <th>시설포도탄저병_초기</th>\n",
       "      <th>일소피해_말기</th>\n",
       "      <th>파프리카_정상</th>\n",
       "      <th>파프리카흰가루병_말기</th>\n",
       "      <th>파프리카흰가루병_중기</th>\n",
       "      <th>파프리카흰가루병_초기</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>시설포도_정상</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시설포도노균병_중기</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시설포도노균병_초기</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시설포도탄저병_초기</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>일소피해_말기</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>일소피해_초기</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>축과병_초기</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카_정상</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카흰가루병_말기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카흰가루병_중기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카흰가루병_초기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds        시설포도_정상  시설포도노균병_중기  시설포도탄저병_초기  일소피해_말기  파프리카_정상  파프리카흰가루병_말기  \\\n",
       "answer                                                                        \n",
       "시설포도_정상           36           0           0        0        1            0   \n",
       "시설포도노균병_중기         0           2           0        0        0            0   \n",
       "시설포도노균병_초기         2           0           0        0        0            0   \n",
       "시설포도탄저병_초기         1           0           4        0        0            0   \n",
       "일소피해_말기            1           0           0        0        0            0   \n",
       "일소피해_초기            1           0           0        0        0            0   \n",
       "축과병_초기             1           0           0        0        0            0   \n",
       "파프리카_정상            0           0           0        0       32            0   \n",
       "파프리카흰가루병_말기        0           0           0        1        3            1   \n",
       "파프리카흰가루병_중기        0           0           0        0        0            0   \n",
       "파프리카흰가루병_초기        0           0           0        0        2            0   \n",
       "\n",
       "preds        파프리카흰가루병_중기  파프리카흰가루병_초기  \n",
       "answer                                 \n",
       "시설포도_정상                0            2  \n",
       "시설포도노균병_중기             0            0  \n",
       "시설포도노균병_초기             0            0  \n",
       "시설포도탄저병_초기             0            0  \n",
       "일소피해_말기                0            0  \n",
       "일소피해_초기                0            0  \n",
       "축과병_초기                 0            0  \n",
       "파프리카_정상                0            0  \n",
       "파프리카흰가루병_말기            1            0  \n",
       "파프리카흰가루병_중기            0            3  \n",
       "파프리카흰가루병_초기            1            5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = np.array([label_description[label_decoder[int(val)]] for val in y_test])\n",
    "predss = np.array([label_description[label_decoder[int(val)]] for val in y_pred])\n",
    "\n",
    "new_crosstab = pd.crosstab(answer, predss, rownames=['answer'], colnames=['preds'])\n",
    "new_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  5  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  1  1  0  0  0  0  0  1  0]\n",
      " [ 1  2  0  0 36  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.842     1.000     0.914        32\n",
      "           1      0.500     0.625     0.556         8\n",
      "           2      0.000     0.000     0.000         3\n",
      "           3      1.000     0.167     0.286         6\n",
      "          19      0.857     0.923     0.889        39\n",
      "          20      1.000     0.800     0.889         5\n",
      "          23      0.000     0.000     0.000         2\n",
      "          24      1.000     1.000     1.000         2\n",
      "          26      0.000     0.000     0.000         1\n",
      "          28      0.000     0.000     0.000         1\n",
      "          29      0.000     0.000     0.000         1\n",
      "\n",
      "    accuracy                          0.800       100\n",
      "   macro avg      0.473     0.410     0.412       100\n",
      "weighted avg      0.774     0.800     0.765       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8865460eab3b8858828539624ef2f45d875655b94242e338bcb660acf08eeb38"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

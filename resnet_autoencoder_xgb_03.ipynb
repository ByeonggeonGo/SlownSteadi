{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 + autoencoder로 각각 이미지와 시계열 셋을 전처리한 후 XGB로 파인튠하여 최종분류\n",
    "*부트스트랩으로 언밸런스데이터 오버샘플링해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*해결과제\n",
    "1. 10번쨰열 결측치 처리\n",
    "2. 데이터 중복시간있는것 처리 -> 10번째열 있는 자료만 쓰려고 하였으나 10번쨰열이 없는 데이터도 상당히 존재함\n",
    "3. 1~9 -> 10 하는 간단한 모델 적합 후 결측치 처리하는 방향으로 고려중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import json \n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 sample data는 파프리카와 시설포도 2종류의 작물만 존재\n",
    "label_description = {\n",
    " '3_00_0': '파프리카_정상',\n",
    " '3_a9_1': '파프리카흰가루병_초기',\n",
    " '3_a9_2': '파프리카흰가루병_중기',\n",
    " '3_a9_3': '파프리카흰가루병_말기',\n",
    " '3_a10_1': '파프리카잘록병_초기',\n",
    " '3_a10_2': '파프리카잘록병_중기',\n",
    " '3_a10_3': '파프리카잘록병_말기',\n",
    " '3_b3_1': '칼슘결핍_초기',\n",
    " '3_b3_2': '칼슘결핍_중기',\n",
    " '3_b3_3': '칼슘결핍_말기',\n",
    " '3_b6_1': '다량원소결핍 (N)_초기',\n",
    " '3_b6_2': '다량원소결핍 (N)_중기',\n",
    " '3_b6_3': '다량원소결핍 (N)_말기',\n",
    " '3_b7_1': '다량원소결핍 (P)_초기',\n",
    " '3_b7_2': '다량원소결핍 (P)_중기',\n",
    " '3_b7_3': '다량원소결핍 (P)_말기',\n",
    " '3_b8_1': '다량원소결핍 (K)_초기',\n",
    " '3_b8_2': '다량원소결핍 (K)_중기',\n",
    " '3_b8_3': '다량원소결핍 (K)_말기',\n",
    " '6_00_0': '시설포도_정상',\n",
    " '6_a11_1': '시설포도탄저병_초기',\n",
    " '6_a11_2': '시설포도탄저병_중기',\n",
    " '6_a11_3': '시설포도탄저병_말기',\n",
    " '6_a12_1': '시설포도노균병_초기',\n",
    " '6_a12_2': '시설포도노균병_중기',\n",
    " '6_a12_3': '시설포도노균병_말기',\n",
    " '6_b4_1': '일소피해_초기',\n",
    " '6_b4_2': '일소피해_중기',\n",
    " '6_b4_3': '일소피해_말기',\n",
    " '6_b5_1': '축과병_초기',\n",
    " '6_b5_2': '축과병_중기',\n",
    " '6_b5_3': '축과병_말기',\n",
    "}\n",
    "\n",
    "label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
    "label_decoder = {val:key for key, val in label_encoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataController():\n",
    "    def __init__(self,csvfeatures,csvfeaturedict):\n",
    "        self.csvfeatures = csvfeatures\n",
    "        self.csvfeaturedict = csvfeaturedict\n",
    "    \n",
    "    def road_csv(self,foldnam,timenum):\n",
    "        df = pd.read_csv(foldnam)\n",
    "        return df.loc[:timenum-1,self.csvfeatures]      #csv파일 제일 짧은게 291개임 오류인지는 모르겠으나 일단 최소길이로 통일하여 처리\n",
    "    \n",
    "    def scaling(self,minmaxdic,df):\n",
    "        for col in minmaxdic.keys():\n",
    "            df.loc[:,col] = df.loc[:,col] - self.csvfeaturedict[col][0]\n",
    "            df.loc[:,col] = df.loc[:,col] / (self.csvfeaturedict[col][1]-self.csvfeaturedict[col][0])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def getimage(self,imgpath):\n",
    "        img = cv2.imread(imgpath)\n",
    "        img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "        img = img.astype(np.float32)/255  ##픽셀값을 0~1사이로 정규화\n",
    "        # img = np.transpose(img, (2,0,1))\n",
    "        return img\n",
    "    \n",
    "    def getlable(self,jsonpath):\n",
    "        with open(jsonpath, 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "\n",
    "        crop = json_file['annotations']['crop']\n",
    "        disease = json_file['annotations']['disease']\n",
    "        risk = json_file['annotations']['risk']\n",
    "        label = f'{crop}_{disease}_{risk}'\n",
    "        return label\n",
    "    \n",
    "    def getdata(self,datapath,timenum,featnum):\n",
    "        imagesize = 224\n",
    "        \n",
    "        \n",
    "        csvarr = np.empty((0,timenum,featnum), float)\n",
    "        imgarr = np.empty((0,imagesize,imagesize,3), float)\n",
    "        lablearr = np.array([])\n",
    "        \n",
    "        # predictor = np.append(predictor,ndf.reshape(-1,timenum,featnum),axis = 0)\n",
    "        \n",
    "        for ind,i in enumerate(datapath):\n",
    "            \n",
    "            if glob(i + '/*.csv') == []:  #10462폴더 비어있음. 다음에 확인해보기\n",
    "                pass\n",
    "            else:\n",
    "                csvpath = glob(i + '/*.csv')[0]\n",
    "                imgpath = glob(i + '/*.jpg')[0]\n",
    "                jsonpath = glob(i + '/*.json')[0]\n",
    "                # con = DataController()\n",
    "                df = self.road_csv(csvpath,timenum)\n",
    "                df2 = self.scaling(self.csvfeaturedict,df).to_numpy().reshape(-1,timenum,featnum)\n",
    "                imgdata = self.getimage(imgpath).reshape(-1,imagesize,imagesize,3)\n",
    "                label = label_encoder[self.getlable(jsonpath)]\n",
    "                # label = self.getlable(jsonpath)\n",
    "                \n",
    "                csvarr = np.append(csvarr,df2, axis = 0)\n",
    "                imgarr = np.append(imgarr,imgdata, axis = 0)\n",
    "                lablearr = np.append(lablearr,label)\n",
    "            \n",
    "        return [csvarr,imgarr],lablearr\n",
    "    \n",
    "    def set_allfilelist_stratified_by_gruop(self,datapath):\n",
    "        #empty list of label\n",
    "        lablearr = np.array([])\n",
    "        dic_by_group = {}\n",
    "        \n",
    "        #loop to make whole array of label\n",
    "        for ind,i in enumerate(datapath):\n",
    "            \n",
    "             if glob(i + '/*.json') == []:  #10462폴더 비어있음. 다음에 확인해보기\n",
    "                pass\n",
    "            \n",
    "             else:\n",
    "                jsonpath = glob(i + '/*.json')[0]\n",
    "                label = label_encoder[self.getlable(jsonpath)]\n",
    "                \n",
    "                # lablearr = np.append(lablearr,label)\n",
    "                labelstr = \"%s\"%label\n",
    "                try: dic_by_group[labelstr].append(i)\n",
    "                except: dic_by_group[labelstr] = [i]\n",
    "                \n",
    "               \n",
    "        return dic_by_group\n",
    "    \n",
    "    def get_pathlist_stratified_dataset(self,allpath,stratified_flies_dict,sample_num_of_trainset):\n",
    "        files_for_dataset = {'train':[], 'test':[]}\n",
    "        dataset_ratio = sample_num_of_trainset/len(allpath)\n",
    "        \n",
    "        for key, value in stratified_flies_dict.items():\n",
    "            \n",
    "          if len(value) == 1:\n",
    "              files_for_dataset['train'].append(value[0])\n",
    "              \n",
    "              \n",
    "          else:\n",
    "              train_num_of_group = int(np.round(len(value)*dataset_ratio))\n",
    "              \n",
    "              train_num = [True]*train_num_of_group\n",
    "              test_num = [False]*(len(value)-train_num_of_group)\n",
    "              set_divide_index = train_num+test_num\n",
    "              random.shuffle(set_divide_index)\n",
    "              \n",
    "              for ind,i in enumerate(set_divide_index):\n",
    "                  if i:\n",
    "                      files_for_dataset['train'].append(value[ind])\n",
    "                  else:\n",
    "                      files_for_dataset['test'].append(value[ind])\n",
    "                      \n",
    "        return files_for_dataset\n",
    "                      \n",
    "              \n",
    "              \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498/498 [00:01<00:00, 259.31it/s]\n"
     ]
    }
   ],
   "source": [
    "###############parameters######################\n",
    "###############################################\n",
    "#프로젝트에 있는 모든 데이터폴터 불러오기\n",
    "# 분석에 사용할 feature 선택\n",
    "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
    "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
    "\n",
    "# csv_files = sorted(glob('sample_data/*/*.csv'))\n",
    "allfile = glob(path + '\\\\sample_data\\\\sample_data\\\\*\\\\*.csv')\n",
    "csv_files = sorted(allfile)\n",
    "\n",
    "temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
    "max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "\n",
    "# feature 별 최대값, 최솟값 계산\n",
    "for csv in tqdm(csv_files[1:]):\n",
    "    temp_csv = pd.read_csv(csv)[csv_features]\n",
    "    temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "    max_arr = np.max([max_arr,temp_max], axis=0)\n",
    "    min_arr = np.min([min_arr,temp_min], axis=0)\n",
    "\n",
    "# feature 별 최대값, 최솟값 dictionary 생성\n",
    "csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
    "csv_feature_dict\n",
    "#\n",
    "time_lag = 260\n",
    "number_of_feature = 9\n",
    "number_of_trainset = 400\n",
    "\n",
    "##################makedataset###################\n",
    "################################################\n",
    "# 데이터 컨트롤러\n",
    "dacon = DataController(csv_features,csv_feature_dict)\n",
    "##############train, test file List############\n",
    "\n",
    "###1. not stratified\n",
    "# data_files_list = glob(path + '\\\\sample_data\\\\sample_data\\\\*')\n",
    "# #셔플\n",
    "# random.shuffle(data_files_list)\n",
    "# #앞에서 300번째까지 트레인셋으로\n",
    "# trainfiles = data_files_list[:number_of_trainset]\n",
    "# #나머지는 테스트셋으로\n",
    "# testfiles = data_files_list[number_of_trainset:]\n",
    "\n",
    "###2. stratified\n",
    "data_files_list = glob(path + '\\\\sample_data\\\\sample_data\\\\*')\n",
    "tempset = dacon.set_allfilelist_stratified_by_gruop(data_files_list)\n",
    "tempdic = dacon.get_pathlist_stratified_dataset(data_files_list,tempset,number_of_trainset)\n",
    "trainfiles = tempdic['train']\n",
    "testfiles = tempdic['test']\n",
    "\n",
    "###set dataset\n",
    "x_train,y_train = dacon.getdata(trainfiles,time_lag,number_of_feature)\n",
    "x_test,y_test = dacon.getdata(testfiles,time_lag,number_of_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 그룹별 개수\n",
      "group 19 - 6_00_0 - 시설포도_정상 : 196\n",
      "group 0 - 3_00_0 - 파프리카_정상 : 169\n",
      "group 1 - 3_a9_1 - 파프리카흰가루병_초기 : 47\n",
      "group 2 - 3_a9_2 - 파프리카흰가루병_중기 : 35\n",
      "group 24 - 6_a12_2 - 시설포도노균병_중기 : 13\n",
      "group 26 - 6_b4_1 - 일소피해_초기 : 3\n",
      "group 3 - 3_a9_3 - 파프리카흰가루병_말기 : 12\n",
      "group 23 - 6_a12_1 - 시설포도노균병_초기 : 3\n",
      "group 20 - 6_a11_1 - 시설포도탄저병_초기 : 10\n",
      "group 4 - 3_a10_1 - 파프리카잘록병_초기 : 1\n",
      "group 6 - 3_a10_3 - 파프리카잘록병_말기 : 3\n",
      "group 28 - 6_b4_3 - 일소피해_말기 : 3\n",
      "group 29 - 6_b5_1 - 축과병_초기 : 2\n",
      "group 21 - 6_a11_2 - 시설포도탄저병_중기 : 1\n",
      "group 5 - 3_a10_2 - 파프리카잘록병_중기 : 1\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터셋 그룹별 개수\")\n",
    "for i,value in tempset.items():\n",
    "    print(\"group \"+i+\" - \"+label_decoder[int(i)]+\" - \"+label_description[label_decoder[int(i)]]+\" :\",len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eencoder(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Eencoder, self).__init__()\n",
    "        self.block1_layer1 = tf.keras.layers.Conv1D(9, 81, activation='relu',)#input_shape=input_shape[1:])\n",
    "        self.block1_layer2 = tf.keras.layers.Conv1D(18, 81, activation='relu',)#input_shape=input_shape[1:])\n",
    "        self.block1_layer3 = tf.keras.layers.Conv1D(36, 100, activation='relu',)#input_shape=input_shape[1:])\n",
    "         \n",
    "    def call(self, inputs):\n",
    "        #LSTM파트\n",
    "        lstm_x = self.block1_layer1(inputs)\n",
    "        lstm_x = tf.nn.relu(lstm_x)\n",
    "        lstm_x = self.block1_layer2(lstm_x)\n",
    "        lstm_x = tf.nn.relu(lstm_x)\n",
    "        lstm_x = self.block1_layer3(lstm_x)\n",
    "        lstm_x = tf.nn.relu(lstm_x)\n",
    "        \n",
    "        return lstm_x\n",
    "class Ddecoder(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Ddecoder, self).__init__()\n",
    "        self.block1_layer1 = tf.keras.layers.Conv1DTranspose(3, 81, activation='relu',)#input_shape=input_shape[1:])\n",
    "        self.block1_layer2 = tf.keras.layers.Conv1DTranspose(6, 81, activation='relu',)#input_shape=input_shape[1:])\n",
    "        self.block1_layer3 = tf.keras.layers.Conv1DTranspose(9, 100, activation='relu',)#input_shape=input_shape[1:])\n",
    "        \n",
    "         \n",
    "    def call(self, inputs):\n",
    "        #LSTM파트\n",
    "        x = self.block1_layer1(inputs)\n",
    "        \n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.block1_layer2(x)\n",
    "        \n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.block1_layer3(x)\n",
    "       \n",
    "        return x\n",
    "\n",
    "# Eencoder()(x_train[0][:2,:,:]).shape\n",
    "# Ddecoder()(Eencoder()(x_train[0][:2,:,:]))\n",
    "\n",
    "class Autoencoder(tf.keras.Model): \n",
    "  def __init__(self,): \n",
    "    super(Autoencoder, self).__init__() \n",
    "    self.encoder = Eencoder() \n",
    "    self.decoder = Ddecoder() \n",
    "  \n",
    "  def call(self, input): \n",
    "    code = self.encoder(input) \n",
    "    reconstructed = self.decoder(code) \n",
    "    return reconstructed\n",
    "\n",
    "def loss(model, original): \n",
    "  reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(model(original), original))) \n",
    "  return reconstruction_error\n",
    "\n",
    "def train(loss, model, opt, original): \n",
    "  with tf.GradientTape() as tape: \n",
    "    gradients = tape.gradient(loss(model, original), model.trainable_variables) \n",
    "    gradient_variables = zip(gradients, model.trainable_variables) \n",
    "    opt.apply_gradients(gradient_variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 53ms/step - loss: 0.2376\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2119\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2156\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1826\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1369\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1100\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1036\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0913\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0819\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0743\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0664\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0596\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0550\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0516\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0486\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0460\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0439\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0423\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0410\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0399\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0389\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0381\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0373\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0366\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0360\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.0355\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0350\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0346\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0342\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0339\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0335\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0333\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0330\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0327\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0325\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0323\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0320\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0318\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0316\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0314\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0312\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0310\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0308\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.0307\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0305\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0303\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0301\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0299\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0296\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de8813ffd0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automodel = Autoencoder()\n",
    "opt = tf.optimizers.Adam()\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "automodel.compile(optimizer=opt, loss=loss_fn)\n",
    "automodel.fit(x_train[0], x_train[0], \n",
    "                 batch_size=100, \n",
    "                 epochs=50,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset에 오토인코더 손실함수 테스트:  tf.Tensor(0.029283952, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_pred = automodel(x_test[0])\n",
    "print(\"testset에 오토인코더 손실함수 테스트: \",loss_fn(x_test[0],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprmodel(keras.Model):\n",
    "    def __init__(self, imgmodel,autoencoder,name = None):\n",
    "        super(preprmodel, self).__init__()\n",
    "        self.imgmodel = imgmodel\n",
    "        self.autoencoder = autoencoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1 = self.imgmodel(inputs[1])\n",
    "        x2 = self.autoencoder.encoder(inputs[0]).numpy().reshape(-1,36)\n",
    "\n",
    "\n",
    "        x = tf.concat([x1,x2],axis=1)\n",
    "        return(x)\n",
    "model_RESNET50 = ResNet50(weights='imagenet')\n",
    "prepromodel = preprmodel(model_RESNET50,automodel)\n",
    "x_prime_train = prepromodel(x_train)\n",
    "x_prime_test = prepromodel(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(colsample_bytree=0.7, objective='multi:softprob',\n",
       "              random_state=100, scale_pos_weight=0.2, subsample=0.7)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=100, subsample= 0.7, colsample_bytree=0.7, scale_pos_weight=0.2)\n",
    "xgb.fit(x_prime_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>시설포도_정상</th>\n",
       "      <th>시설포도노균병_중기</th>\n",
       "      <th>시설포도탄저병_초기</th>\n",
       "      <th>일소피해_말기</th>\n",
       "      <th>일소피해_초기</th>\n",
       "      <th>파프리카_정상</th>\n",
       "      <th>파프리카흰가루병_말기</th>\n",
       "      <th>파프리카흰가루병_중기</th>\n",
       "      <th>파프리카흰가루병_초기</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>시설포도_정상</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시설포도노균병_중기</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시설포도노균병_초기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시설포도탄저병_초기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>일소피해_말기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>일소피해_초기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카_정상</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카잘록병_말기</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카흰가루병_말기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카흰가루병_중기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카흰가루병_초기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds        시설포도_정상  시설포도노균병_중기  시설포도탄저병_초기  일소피해_말기  일소피해_초기  파프리카_정상  \\\n",
       "answer                                                                    \n",
       "시설포도_정상           39           0           0        0        0        0   \n",
       "시설포도노균병_중기         0           3           0        0        0        0   \n",
       "시설포도노균병_초기         0           0           0        0        0        0   \n",
       "시설포도탄저병_초기         0           0           2        0        0        0   \n",
       "일소피해_말기            0           0           0        1        0        0   \n",
       "일소피해_초기            0           0           0        0        1        0   \n",
       "파프리카_정상            0           0           0        0        0       34   \n",
       "파프리카잘록병_말기         1           0           0        0        0        0   \n",
       "파프리카흰가루병_말기        0           0           0        0        0        0   \n",
       "파프리카흰가루병_중기        0           0           0        0        0        0   \n",
       "파프리카흰가루병_초기        0           0           0        0        0        0   \n",
       "\n",
       "preds        파프리카흰가루병_말기  파프리카흰가루병_중기  파프리카흰가루병_초기  \n",
       "answer                                              \n",
       "시설포도_정상                0            0            0  \n",
       "시설포도노균병_중기             0            0            0  \n",
       "시설포도노균병_초기             0            1            0  \n",
       "시설포도탄저병_초기             0            0            0  \n",
       "일소피해_말기                0            0            0  \n",
       "일소피해_초기                0            0            0  \n",
       "파프리카_정상                0            0            0  \n",
       "파프리카잘록병_말기             0            0            0  \n",
       "파프리카흰가루병_말기            1            0            1  \n",
       "파프리카흰가루병_중기            0            0            7  \n",
       "파프리카흰가루병_초기            0            3            6  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=xgb.predict(x_prime_test)\n",
    "answer = np.array([label_description[label_decoder[int(val)]] for val in y_test])\n",
    "predss = np.array([label_description[label_decoder[int(val)]] for val in y_pred])\n",
    "\n",
    "new_crosstab = pd.crosstab(answer, predss, rownames=['answer'], colnames=['preds'])\n",
    "new_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  6  3  0  0  0  0  0  0  0  0]\n",
      " [ 0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 39  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      1.000     1.000     1.000        34\n",
      "         1.0      0.429     0.667     0.522         9\n",
      "         2.0      0.000     0.000     0.000         7\n",
      "         3.0      1.000     0.500     0.667         2\n",
      "         6.0      0.000     0.000     0.000         1\n",
      "        19.0      0.975     1.000     0.987        39\n",
      "        20.0      1.000     1.000     1.000         2\n",
      "        23.0      0.000     0.000     0.000         1\n",
      "        24.0      1.000     1.000     1.000         3\n",
      "        26.0      1.000     1.000     1.000         1\n",
      "        28.0      1.000     1.000     1.000         1\n",
      "\n",
      "    accuracy                          0.870       100\n",
      "   macro avg      0.673     0.652     0.652       100\n",
      "weighted avg      0.849     0.870     0.855       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8865460eab3b8858828539624ef2f45d875655b94242e338bcb660acf08eeb38"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

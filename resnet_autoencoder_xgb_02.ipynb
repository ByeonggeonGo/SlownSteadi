{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 + autoencoder로 각각 이미지와 시계열 셋을 전처리한 후 XGB로 파인튠하여 최종분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*해결과제\n",
    "1. 10번쨰열 결측치 처리\n",
    "2. 데이터 중복시간있는것 처리 -> 10번째열 있는 자료만 쓰려고 하였으나 10번쨰열이 없는 데이터도 상당히 존재함\n",
    "3. 1~9 -> 10 하는 간단한 모델 적합 후 결측치 처리하는 방향으로 고려중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import json \n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 sample data는 파프리카와 시설포도 2종류의 작물만 존재\n",
    "label_description = {\n",
    " '3_00_0': '파프리카_정상',\n",
    " '3_a9_1': '파프리카흰가루병_초기',\n",
    " '3_a9_2': '파프리카흰가루병_중기',\n",
    " '3_a9_3': '파프리카흰가루병_말기',\n",
    " '3_a10_1': '파프리카잘록병_초기',\n",
    " '3_a10_2': '파프리카잘록병_중기',\n",
    " '3_a10_3': '파프리카잘록병_말기',\n",
    " '3_b3_1': '칼슘결핍_초기',\n",
    " '3_b3_2': '칼슘결핍_중기',\n",
    " '3_b3_3': '칼슘결핍_말기',\n",
    " '3_b6_1': '다량원소결핍 (N)_초기',\n",
    " '3_b6_2': '다량원소결핍 (N)_중기',\n",
    " '3_b6_3': '다량원소결핍 (N)_말기',\n",
    " '3_b7_1': '다량원소결핍 (P)_초기',\n",
    " '3_b7_2': '다량원소결핍 (P)_중기',\n",
    " '3_b7_3': '다량원소결핍 (P)_말기',\n",
    " '3_b8_1': '다량원소결핍 (K)_초기',\n",
    " '3_b8_2': '다량원소결핍 (K)_중기',\n",
    " '3_b8_3': '다량원소결핍 (K)_말기',\n",
    " '6_00_0': '시설포도_정상',\n",
    " '6_a11_1': '시설포도탄저병_초기',\n",
    " '6_a11_2': '시설포도탄저병_중기',\n",
    " '6_a11_3': '시설포도탄저병_말기',\n",
    " '6_a12_1': '시설포도노균병_초기',\n",
    " '6_a12_2': '시설포도노균병_중기',\n",
    " '6_a12_3': '시설포도노균병_말기',\n",
    " '6_b4_1': '일소피해_초기',\n",
    " '6_b4_2': '일소피해_중기',\n",
    " '6_b4_3': '일소피해_말기',\n",
    " '6_b5_1': '축과병_초기',\n",
    " '6_b5_2': '축과병_중기',\n",
    " '6_b5_3': '축과병_말기',\n",
    "}\n",
    "\n",
    "label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
    "label_decoder = {val:key for key, val in label_encoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataController():\n",
    "    def __init__(self,csvfeatures,csvfeaturedict):\n",
    "        self.csv_features = csvfeatures\n",
    "        self.csv_feature_dict = csvfeaturedict\n",
    "    \n",
    "    def road_csv(self,foldnam,timenum):\n",
    "        df = pd.read_csv(foldnam)\n",
    "        return df.loc[:timenum-1,self.csv_features]      #csv파일 제일 짧은게 291개임 오류인지는 모르겠으나 일단 최소길이로 통일하여 처리\n",
    "    \n",
    "    def scaling(self,minmaxdic,df):\n",
    "        for col in minmaxdic.keys():\n",
    "            df.loc[:,col] = df.loc[:,col] - csv_feature_dict[col][0]\n",
    "            df.loc[:,col] = df.loc[:,col] / (csv_feature_dict[col][1]-csv_feature_dict[col][0])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def getimage(self,imgpath):\n",
    "        img = cv2.imread(imgpath)\n",
    "        img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "        img = img.astype(np.float32)/255  ##픽셀값을 0~1사이로 정규화\n",
    "        # img = np.transpose(img, (2,0,1))\n",
    "        return img\n",
    "    \n",
    "    def getlable(self,jsonpath):\n",
    "        with open(jsonpath, 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "\n",
    "        crop = json_file['annotations']['crop']\n",
    "        disease = json_file['annotations']['disease']\n",
    "        risk = json_file['annotations']['risk']\n",
    "        label = f'{crop}_{disease}_{risk}'\n",
    "        return label\n",
    "    \n",
    "    def getdata(self,datapath,timenum,featnum):\n",
    "\n",
    "        csvarr = np.empty((0,timenum,featnum), float)\n",
    "        imgarr = np.empty((0,224,224,3), float)\n",
    "        lablearr = np.array([])\n",
    "        \n",
    "        # predictor = np.append(predictor,ndf.reshape(-1,timenum,featnum),axis = 0)\n",
    "        \n",
    "        for ind,i in enumerate(datapath):\n",
    "            \n",
    "            if glob(i + '/*.csv') == []:  #10462폴더 비어있음. 다음에 확인해보기\n",
    "                pass\n",
    "            else:\n",
    "                csvpath = glob(i + '/*.csv')[0]\n",
    "                imgpath = glob(i + '/*.jpg')[0]\n",
    "                jsonpath = glob(i + '/*.json')[0]\n",
    "                # con = DataController()\n",
    "                df = self.road_csv(csvpath,timenum)\n",
    "                df2 = self.scaling(csv_feature_dict,df).to_numpy().reshape(-1,timenum,featnum)\n",
    "                imgdata = self.getimage(imgpath).reshape(-1,224,224,3)\n",
    "                label = label_encoder[self.getlable(jsonpath)]\n",
    "                # label = self.getlable(jsonpath)\n",
    "                \n",
    "                csvarr = np.append(csvarr,df2, axis = 0)\n",
    "                imgarr = np.append(imgarr,imgdata, axis = 0)\n",
    "                lablearr = np.append(lablearr,label)\n",
    "            \n",
    "        return [csvarr,imgarr],lablearr\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############parameters######################\n",
    "###############################################\n",
    "#프로젝트에 있는 모든 데이터폴터 불러오기\n",
    "# 분석에 사용할 feature 선택\n",
    "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
    "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
    "\n",
    "# csv_files = sorted(glob('sample_data/*/*.csv'))\n",
    "allfile = glob(path + '\\\\sample_data\\\\sample_data\\\\*\\\\*.csv')\n",
    "csv_files = sorted(allfile)\n",
    "\n",
    "temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
    "max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "\n",
    "# feature 별 최대값, 최솟값 계산\n",
    "for csv in tqdm(csv_files[1:]):\n",
    "    temp_csv = pd.read_csv(csv)[csv_features]\n",
    "    temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "    max_arr = np.max([max_arr,temp_max], axis=0)\n",
    "    min_arr = np.min([min_arr,temp_min], axis=0)\n",
    "\n",
    "# feature 별 최대값, 최솟값 dictionary 생성\n",
    "csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
    "csv_feature_dict\n",
    "#\n",
    "time_lag = 260\n",
    "number_of_feature = 9\n",
    "number_of_trainset = 400\n",
    "\n",
    "##################makedataset###################\n",
    "################################################\n",
    "\n",
    "#path + '\\\\sample_data\\\\sample_data\\\\*\\\\*.csv'\n",
    "data_files_list = glob(path + '\\\\sample_data\\\\sample_data\\\\*')\n",
    "#셔플\n",
    "random.shuffle(data_files_list)\n",
    "#앞에서 300번째까지 트레인셋으로\n",
    "trainfiles = data_files_list[:number_of_trainset]\n",
    "#나머지는 테스트셋으로\n",
    "testfiles = data_files_list[number_of_trainset:]\n",
    "\n",
    "# 데이터 컨트롤러\n",
    "dacon = DataController(csv_features,csv_feature_dict)\n",
    "# 배치화된 데이터셋 만들기\n",
    "# test셋용으로는 train = False로 하여 배치안생성하게됨\n",
    "x_train,y_train = dacon.getdata(trainfiles,time_lag,number_of_feature)\n",
    "x_test,y_test = dacon.getdata(testfiles,time_lag,number_of_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eencoder(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Eencoder, self).__init__()\n",
    "        self.block1_layer1 = tf.keras.layers.Conv1D(9, 81, activation='relu',)#input_shape=input_shape[1:])\n",
    "        self.block1_layer2 = tf.keras.layers.Conv1D(18, 81, activation='relu',)#input_shape=input_shape[1:])\n",
    "        self.block1_layer3 = tf.keras.layers.Conv1D(36, 100, activation='relu',)#input_shape=input_shape[1:])\n",
    "         \n",
    "    def call(self, inputs):\n",
    "        #LSTM파트\n",
    "        lstm_x = self.block1_layer1(inputs)\n",
    "        lstm_x = tf.nn.relu(lstm_x)\n",
    "        lstm_x = self.block1_layer2(lstm_x)\n",
    "        lstm_x = tf.nn.relu(lstm_x)\n",
    "        lstm_x = self.block1_layer3(lstm_x)\n",
    "        lstm_x = tf.nn.relu(lstm_x)\n",
    "        \n",
    "        return lstm_x\n",
    "class Ddecoder(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Ddecoder, self).__init__()\n",
    "        self.block1_layer1 = tf.keras.layers.Conv1DTranspose(3, 81, activation='relu',)#input_shape=input_shape[1:])\n",
    "        self.block1_layer2 = tf.keras.layers.Conv1DTranspose(6, 81, activation='relu',)#input_shape=input_shape[1:])\n",
    "        self.block1_layer3 = tf.keras.layers.Conv1DTranspose(9, 100, activation='relu',)#input_shape=input_shape[1:])\n",
    "        \n",
    "         \n",
    "    def call(self, inputs):\n",
    "        #LSTM파트\n",
    "        x = self.block1_layer1(inputs)\n",
    "        \n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.block1_layer2(x)\n",
    "        \n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.block1_layer3(x)\n",
    "       \n",
    "        return x\n",
    "\n",
    "# Eencoder()(x_train[0][:2,:,:]).shape\n",
    "# Ddecoder()(Eencoder()(x_train[0][:2,:,:]))\n",
    "\n",
    "class Autoencoder(tf.keras.Model): \n",
    "  def __init__(self,): \n",
    "    super(Autoencoder, self).__init__() \n",
    "    self.encoder = Eencoder() \n",
    "    self.decoder = Ddecoder() \n",
    "  \n",
    "  def call(self, input): \n",
    "    code = self.encoder(input) \n",
    "    reconstructed = self.decoder(code) \n",
    "    return reconstructed\n",
    "\n",
    "def loss(model, original): \n",
    "  reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(model(original), original))) \n",
    "  return reconstruction_error\n",
    "\n",
    "def train(loss, model, opt, original): \n",
    "  with tf.GradientTape() as tape: \n",
    "    gradients = tape.gradient(loss(model, original), model.trainable_variables) \n",
    "    gradient_variables = zip(gradients, model.trainable_variables) \n",
    "    opt.apply_gradients(gradient_variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 55ms/step - loss: 0.2649\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1843\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1344\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1111\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0906\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0748\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0640\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0566\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0514\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0477\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0450\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0428\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0411\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0398\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0387\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0378\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0370\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0364\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0357\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a92a1f1940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automodel = Autoencoder()\n",
    "opt = tf.optimizers.Adam()\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "automodel.compile(optimizer=opt, loss=loss_fn)\n",
    "automodel.fit(x_train[0], x_train[0], \n",
    "                 batch_size=100, \n",
    "                 epochs=20,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset에 오토인코더 손실함수 테스트:  tf.Tensor(0.032171927, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_pred = automodel(x_test[0])\n",
    "print(\"testset에 오토인코더 손실함수 테스트: \",loss_fn(x_test[0],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprmodel(keras.Model):\n",
    "    def __init__(self, imgmodel,autoencoder,name = None):\n",
    "        super(preprmodel, self).__init__()\n",
    "        self.imgmodel = imgmodel\n",
    "        self.autoencoder = autoencoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1 = self.imgmodel(inputs[1])\n",
    "        x2 = self.autoencoder.encoder(inputs[0]).numpy().reshape(-1,36)\n",
    "\n",
    "\n",
    "        x = tf.concat([x1,x2],axis=1)\n",
    "        return(x)\n",
    "model_RESNET50 = ResNet50(weights='imagenet')\n",
    "prepromodel = preprmodel(model_RESNET50,automodel)\n",
    "x_prime_train = prepromodel(x_train)\n",
    "x_prime_test = prepromodel(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(colsample_bytree=0.7, objective='multi:softprob',\n",
       "              random_state=100, scale_pos_weight=0.2, subsample=0.7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=100, subsample= 0.7, colsample_bytree=0.7, scale_pos_weight=0.2)\n",
    "xgb.fit(x_prime_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>시설포도_정상</th>\n",
       "      <th>시설포도노균병_중기</th>\n",
       "      <th>시설포도탄저병_초기</th>\n",
       "      <th>일소피해_말기</th>\n",
       "      <th>파프리카_정상</th>\n",
       "      <th>파프리카흰가루병_말기</th>\n",
       "      <th>파프리카흰가루병_중기</th>\n",
       "      <th>파프리카흰가루병_초기</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>시설포도_정상</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시설포도노균병_중기</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시설포도탄저병_초기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>일소피해_말기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>축과병_초기</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카_정상</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카흰가루병_말기</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카흰가루병_중기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파프리카흰가루병_초기</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds        시설포도_정상  시설포도노균병_중기  시설포도탄저병_초기  일소피해_말기  파프리카_정상  파프리카흰가루병_말기  \\\n",
       "answer                                                                        \n",
       "시설포도_정상           36           0           0        0        0            0   \n",
       "시설포도노균병_중기         0           3           0        0        0            0   \n",
       "시설포도탄저병_초기         0           0           3        0        0            0   \n",
       "일소피해_말기            0           0           0        1        0            0   \n",
       "축과병_초기             1           0           0        0        0            0   \n",
       "파프리카_정상            0           0           0        0       37            0   \n",
       "파프리카흰가루병_말기        1           0           0        0        0            0   \n",
       "파프리카흰가루병_중기        0           0           0        0        0            1   \n",
       "파프리카흰가루병_초기        1           0           0        0        1            0   \n",
       "\n",
       "preds        파프리카흰가루병_중기  파프리카흰가루병_초기  \n",
       "answer                                 \n",
       "시설포도_정상                0            0  \n",
       "시설포도노균병_중기             0            0  \n",
       "시설포도탄저병_초기             0            0  \n",
       "일소피해_말기                0            0  \n",
       "축과병_초기                 0            0  \n",
       "파프리카_정상                0            0  \n",
       "파프리카흰가루병_말기            1            0  \n",
       "파프리카흰가루병_중기            2            2  \n",
       "파프리카흰가루병_초기            5            5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=xgb.predict(x_prime_test)\n",
    "answer = np.array([label_description[label_decoder[int(val)]] for val in y_test])\n",
    "predss = np.array([label_description[label_decoder[int(val)]] for val in y_pred])\n",
    "\n",
    "new_crosstab = pd.crosstab(answer, predss, rownames=['answer'], colnames=['preds'])\n",
    "new_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  0  0  0  0  0  0  0  0]\n",
      " [ 1  5  5  0  1  0  0  0  0]\n",
      " [ 0  2  2  1  0  0  0  0  0]\n",
      " [ 0  0  1  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 36  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  1  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.974     1.000     0.987        37\n",
      "         1.0      0.714     0.417     0.526        12\n",
      "         2.0      0.250     0.400     0.308         5\n",
      "         3.0      0.000     0.000     0.000         2\n",
      "        19.0      0.923     1.000     0.960        36\n",
      "        20.0      1.000     1.000     1.000         3\n",
      "        24.0      1.000     1.000     1.000         3\n",
      "        28.0      1.000     1.000     1.000         1\n",
      "        29.0      0.000     0.000     0.000         1\n",
      "\n",
      "    accuracy                          0.870       100\n",
      "   macro avg      0.651     0.646     0.642       100\n",
      "weighted avg      0.861     0.870     0.859       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8865460eab3b8858828539624ef2f45d875655b94242e338bcb660acf08eeb38"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

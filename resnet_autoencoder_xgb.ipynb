{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q2qzGO5dtvXB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import os\n",
        "import json \n",
        "import random\n",
        "from xgboost import XGBClassifier, XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noor9-jFuE6O",
        "outputId": "3bf125ac-b00d-43f5-875c-08366ce6fee9"
      },
      "outputs": [],
      "source": [
        "path = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtSLNaLxtvXE",
        "outputId": "22df1c38-4eb6-4fad-b913-f7df847074ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 498/498 [01:21<00:00,  6.12it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'내부 습도 1 최고': [36.5, 100.0],\n",
              " '내부 습도 1 최저': [32.4, 100.0],\n",
              " '내부 습도 1 평균': [34.1, 100.0],\n",
              " '내부 온도 1 최고': [14.5, 47.6],\n",
              " '내부 온도 1 최저': [14.4, 47.0],\n",
              " '내부 온도 1 평균': [14.4, 47.3],\n",
              " '내부 이슬점 최고': [12.8, 31.9],\n",
              " '내부 이슬점 최저': [12.1, 29.1],\n",
              " '내부 이슬점 평균': [12.4, 29.9]}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 분석에 사용할 feature 선택\n",
        "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
        "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
        "\n",
        "# csv_files = sorted(glob('sample_data/*/*.csv'))\n",
        "allfile = glob(path + '\\\\sample_data\\\\sample_data\\\\*\\\\*.csv')\n",
        "csv_files = sorted(allfile)\n",
        "\n",
        "temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
        "max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "\n",
        "# feature 별 최대값, 최솟값 계산\n",
        "for csv in tqdm(csv_files[1:]):\n",
        "    temp_csv = pd.read_csv(csv)[csv_features]\n",
        "    temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "    max_arr = np.max([max_arr,temp_max], axis=0)\n",
        "    min_arr = np.min([min_arr,temp_min], axis=0)\n",
        "\n",
        "# feature 별 최대값, 최솟값 dictionary 생성\n",
        "csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
        "csv_feature_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jZOO842ttvXF"
      },
      "outputs": [],
      "source": [
        "# 제공된 sample data는 파프리카와 시설포도 2종류의 작물만 존재\n",
        "label_description = {\n",
        " '3_00_0': '파프리카_정상',\n",
        " '3_a9_1': '파프리카흰가루병_초기',\n",
        " '3_a9_2': '파프리카흰가루병_중기',\n",
        " '3_a9_3': '파프리카흰가루병_말기',\n",
        " '3_a10_1': '파프리카잘록병_초기',\n",
        " '3_a10_2': '파프리카잘록병_중기',\n",
        " '3_a10_3': '파프리카잘록병_말기',\n",
        " '3_b3_1': '칼슘결핍_초기',\n",
        " '3_b3_2': '칼슘결핍_중기',\n",
        " '3_b3_3': '칼슘결핍_말기',\n",
        " '3_b6_1': '다량원소결핍 (N)_초기',\n",
        " '3_b6_2': '다량원소결핍 (N)_중기',\n",
        " '3_b6_3': '다량원소결핍 (N)_말기',\n",
        " '3_b7_1': '다량원소결핍 (P)_초기',\n",
        " '3_b7_2': '다량원소결핍 (P)_중기',\n",
        " '3_b7_3': '다량원소결핍 (P)_말기',\n",
        " '3_b8_1': '다량원소결핍 (K)_초기',\n",
        " '3_b8_2': '다량원소결핍 (K)_중기',\n",
        " '3_b8_3': '다량원소결핍 (K)_말기',\n",
        " '6_00_0': '시설포도_정상',\n",
        " '6_a11_1': '시설포도탄저병_초기',\n",
        " '6_a11_2': '시설포도탄저병_중기',\n",
        " '6_a11_3': '시설포도탄저병_말기',\n",
        " '6_a12_1': '시설포도노균병_초기',\n",
        " '6_a12_2': '시설포도노균병_중기',\n",
        " '6_a12_3': '시설포도노균병_말기',\n",
        " '6_b4_1': '일소피해_초기',\n",
        " '6_b4_2': '일소피해_중기',\n",
        " '6_b4_3': '일소피해_말기',\n",
        " '6_b5_1': '축과병_초기',\n",
        " '6_b5_2': '축과병_중기',\n",
        " '6_b5_3': '축과병_말기',\n",
        "}\n",
        "\n",
        "label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
        "label_decoder = {val:key for key, val in label_encoder.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zXeK6Pc_SIKS",
        "outputId": "03c05029-363c-4f14-cd0e-a2d185d47b7c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3_a9_1'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_decoder[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MzYWOokPtvXG"
      },
      "outputs": [],
      "source": [
        "class DataController():\n",
        "    def __init__(self,csvfeatures,csvfeaturedict):\n",
        "        self.csv_features = csvfeatures\n",
        "        self.csv_feature_dict = csvfeaturedict\n",
        "    \n",
        "    def road_csv(self,foldnam,timenum):\n",
        "        df = pd.read_csv(foldnam)\n",
        "        return df.loc[:timenum-1,self.csv_features]      #csv파일 제일 짧은게 291개임 오류인지는 모르겠으나 일단 최소길이로 통일하여 처리\n",
        "    \n",
        "    def scaling(self,minmaxdic,df):\n",
        "        for col in minmaxdic.keys():\n",
        "            df.loc[:,col] = df.loc[:,col] - csv_feature_dict[col][0]\n",
        "            df.loc[:,col] = df.loc[:,col] / (csv_feature_dict[col][1]-csv_feature_dict[col][0])\n",
        "        return df\n",
        "    \n",
        "    \n",
        "    def getimage(self,imgpath):\n",
        "        img = cv2.imread(imgpath)\n",
        "        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
        "        img = img.astype(np.float32)/255  ##픽셀값을 0~1사이로 정규화\n",
        "        # img = np.transpose(img, (2,0,1))\n",
        "        return img\n",
        "    \n",
        "    def getlable(self,jsonpath):\n",
        "        with open(jsonpath, 'r') as f:\n",
        "            json_file = json.load(f)\n",
        "\n",
        "        crop = json_file['annotations']['crop']\n",
        "        disease = json_file['annotations']['disease']\n",
        "        risk = json_file['annotations']['risk']\n",
        "        label = f'{crop}_{disease}_{risk}'\n",
        "        return label\n",
        "    \n",
        "    def getdata(self,datapath,timenum,featnum):\n",
        "\n",
        "        csvarr = np.empty((0,timenum,featnum), float)\n",
        "        imgarr = np.empty((0,256,256,3), float)\n",
        "        lablearr = np.array([])\n",
        "        \n",
        "        # predictor = np.append(predictor,ndf.reshape(-1,timenum,featnum),axis = 0)\n",
        "        \n",
        "        for ind,i in enumerate(datapath):\n",
        "            \n",
        "            if glob(i + '/*.csv') == []:  #10462폴더 비어있음. 다음에 확인해보기\n",
        "                pass\n",
        "            else:\n",
        "                csvpath = glob(i + '/*.csv')[0]\n",
        "                imgpath = glob(i + '/*.jpg')[0]\n",
        "                jsonpath = glob(i + '/*.json')[0]\n",
        "                # con = DataController()\n",
        "                df = self.road_csv(csvpath,timenum)\n",
        "                df2 = self.scaling(csv_feature_dict,df).to_numpy().reshape(-1,timenum,featnum)\n",
        "                imgdata = self.getimage(imgpath).reshape(-1,256,256,3)\n",
        "                label = label_encoder[self.getlable(jsonpath)]\n",
        "                # label = self.getlable(jsonpath)\n",
        "                \n",
        "                csvarr = np.append(csvarr,df2, axis = 0)\n",
        "                imgarr = np.append(imgarr,imgdata, axis = 0)\n",
        "                lablearr = np.append(lablearr,label)\n",
        "            \n",
        "        return [csvarr,imgarr],lablearr\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l3BxB-6NSwht"
      },
      "outputs": [],
      "source": [
        "dacon = DataController(csv_features,csv_feature_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "PNR815CWSzwQ",
        "outputId": "3d427431-12b3-482c-e00f-8735cb55e0f7"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-35e84e1f0c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdacon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroad_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: road_csv() missing 2 required positional arguments: 'foldnam' and 'timenum'"
          ]
        }
      ],
      "source": [
        "dacon.road_csv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "talU-dJBtvXH"
      },
      "outputs": [],
      "source": [
        "#프로젝트에 있는 모든 데이터폴터 불러오기\n",
        "data_files = glob(path + '/sample_data/sample_data/*')\n",
        "#셔플\n",
        "random.shuffle(data_files)\n",
        "#앞에서 300번째까지 트레인셋으로\n",
        "trainfiles = data_files[:400]\n",
        "#나머지는 테스트셋으로\n",
        "testfiles = data_files[400:]\n",
        "\n",
        "# 데이터 컨트롤러\n",
        "dacon = DataController(csv_features,csv_feature_dict)\n",
        "# 배치화된 데이터셋 만들기\n",
        "# test셋용으로는 train = False로 하여 배치안생성하게됨\n",
        "x_train,y_train = dacon.getdata(trainfiles,260,9)\n",
        "x_test,y_test = dacon.getdata(testfiles,260,9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu-ThEQELS-2"
      },
      "source": [
        "# **전처리: 오토인코더 시계열 차원 압축 + ResNet50 -> XGBoost**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6vzJyNDKSMJ"
      },
      "source": [
        "* 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a8bPjFm9KQLr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4rl29aMKQLt",
        "outputId": "6ff7e4fd-cad1-4d31-ad2d-fa473739da1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 498/498 [00:03<00:00, 144.49it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'내부 온도 1 평균': [14.4, 47.3],\n",
              " '내부 온도 1 최고': [14.5, 47.6],\n",
              " '내부 온도 1 최저': [14.4, 47.0],\n",
              " '내부 습도 1 평균': [34.1, 100.0],\n",
              " '내부 습도 1 최고': [36.5, 100.0],\n",
              " '내부 습도 1 최저': [32.4, 100.0],\n",
              " '내부 이슬점 평균': [12.4, 29.9],\n",
              " '내부 이슬점 최고': [12.8, 31.9],\n",
              " '내부 이슬점 최저': [12.1, 29.1]}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 분석에 사용할 feature 선택\n",
        "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
        "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
        "\n",
        "# csv_files = sorted(glob('sample_data/*/*.csv'))\n",
        "allfile = glob(path + '\\\\sample_data\\\\sample_data\\\\*\\\\*.csv')\n",
        "csv_files = sorted(allfile)\n",
        "\n",
        "temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
        "max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "\n",
        "# feature 별 최대값, 최솟값 계산\n",
        "for csv in tqdm(csv_files[1:]):\n",
        "    temp_csv = pd.read_csv(csv)[csv_features]\n",
        "    temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "    max_arr = np.max([max_arr,temp_max], axis=0)\n",
        "    min_arr = np.min([min_arr,temp_min], axis=0)\n",
        "\n",
        "# feature 별 최대값, 최솟값 dictionary 생성\n",
        "csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
        "csv_feature_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tiCVdEpAKQLt"
      },
      "outputs": [],
      "source": [
        "# 제공된 sample data는 파프리카와 시설포도 2종류의 작물만 존재\n",
        "label_description = {\n",
        " '3_00_0': '파프리카_정상',\n",
        " '3_a9_1': '파프리카흰가루병_초기',\n",
        " '3_a9_2': '파프리카흰가루병_중기',\n",
        " '3_a9_3': '파프리카흰가루병_말기',\n",
        " '3_a10_1': '파프리카잘록병_초기',\n",
        " '3_a10_2': '파프리카잘록병_중기',\n",
        " '3_a10_3': '파프리카잘록병_말기',\n",
        " '3_b3_1': '칼슘결핍_초기',\n",
        " '3_b3_2': '칼슘결핍_중기',\n",
        " '3_b3_3': '칼슘결핍_말기',\n",
        " '3_b6_1': '다량원소결핍 (N)_초기',\n",
        " '3_b6_2': '다량원소결핍 (N)_중기',\n",
        " '3_b6_3': '다량원소결핍 (N)_말기',\n",
        " '3_b7_1': '다량원소결핍 (P)_초기',\n",
        " '3_b7_2': '다량원소결핍 (P)_중기',\n",
        " '3_b7_3': '다량원소결핍 (P)_말기',\n",
        " '3_b8_1': '다량원소결핍 (K)_초기',\n",
        " '3_b8_2': '다량원소결핍 (K)_중기',\n",
        " '3_b8_3': '다량원소결핍 (K)_말기',\n",
        " '6_00_0': '시설포도_정상',\n",
        " '6_a11_1': '시설포도탄저병_초기',\n",
        " '6_a11_2': '시설포도탄저병_중기',\n",
        " '6_a11_3': '시설포도탄저병_말기',\n",
        " '6_a12_1': '시설포도노균병_초기',\n",
        " '6_a12_2': '시설포도노균병_중기',\n",
        " '6_a12_3': '시설포도노균병_말기',\n",
        " '6_b4_1': '일소피해_초기',\n",
        " '6_b4_2': '일소피해_중기',\n",
        " '6_b4_3': '일소피해_말기',\n",
        " '6_b5_1': '축과병_초기',\n",
        " '6_b5_2': '축과병_중기',\n",
        " '6_b5_3': '축과병_말기',\n",
        "}\n",
        "\n",
        "label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
        "label_decoder = {val:key for key, val in label_encoder.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W4RBgfu6KQLt"
      },
      "outputs": [],
      "source": [
        "class DataController():\n",
        "    def __init__(self,csvfeatures,csvfeaturedict):\n",
        "        self.csv_features = csvfeatures\n",
        "        self.csv_feature_dict = csvfeaturedict\n",
        "    \n",
        "    def road_csv(self,foldnam,timenum):\n",
        "        df = pd.read_csv(foldnam)\n",
        "        return df.loc[:timenum-1,self.csv_features]      #csv파일 제일 짧은게 291개임 오류인지는 모르겠으나 일단 최소길이로 통일하여 처리\n",
        "    \n",
        "    def scaling(self,minmaxdic,df):\n",
        "        for col in minmaxdic.keys():\n",
        "            df.loc[:,col] = df.loc[:,col] - csv_feature_dict[col][0]\n",
        "            df.loc[:,col] = df.loc[:,col] / (csv_feature_dict[col][1]-csv_feature_dict[col][0])\n",
        "        return df\n",
        "    \n",
        "    \n",
        "    def getimage(self,imgpath):\n",
        "        img = cv2.imread(imgpath)\n",
        "        img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
        "        img = img.astype(np.float32)/255  ##픽셀값을 0~1사이로 정규화\n",
        "        # img = np.transpose(img, (2,0,1))\n",
        "        return img\n",
        "    \n",
        "    def getlable(self,jsonpath):\n",
        "        with open(jsonpath, 'r') as f:\n",
        "            json_file = json.load(f)\n",
        "\n",
        "        crop = json_file['annotations']['crop']\n",
        "        disease = json_file['annotations']['disease']\n",
        "        risk = json_file['annotations']['risk']\n",
        "        label = f'{crop}_{disease}_{risk}'\n",
        "        return label\n",
        "    \n",
        "    def getdata(self,datapath,timenum,featnum):\n",
        "\n",
        "        csvarr = np.empty((0,timenum,featnum), float)\n",
        "        imgarr = np.empty((0,224,224,3), float)\n",
        "        lablearr = np.array([])\n",
        "        \n",
        "        # predictor = np.append(predictor,ndf.reshape(-1,timenum,featnum),axis = 0)\n",
        "        \n",
        "        for ind,i in enumerate(datapath):\n",
        "            \n",
        "            if glob(i + '/*.csv') == []:  #10462폴더 비어있음. 다음에 확인해보기\n",
        "                pass\n",
        "            else:\n",
        "                csvpath = glob(i + '/*.csv')[0]\n",
        "                imgpath = glob(i + '/*.jpg')[0]\n",
        "                jsonpath = glob(i + '/*.json')[0]\n",
        "                # con = DataController()\n",
        "                df = self.road_csv(csvpath,timenum)\n",
        "                df2 = self.scaling(csv_feature_dict,df).to_numpy().reshape(-1,timenum,featnum)\n",
        "                imgdata = self.getimage(imgpath).reshape(-1,224,224,3)\n",
        "                label = label_encoder[self.getlable(jsonpath)]\n",
        "                # label = self.getlable(jsonpath)\n",
        "                \n",
        "                csvarr = np.append(csvarr,df2, axis = 0)\n",
        "                imgarr = np.append(imgarr,imgdata, axis = 0)\n",
        "                lablearr = np.append(lablearr,label)\n",
        "            \n",
        "        return [csvarr,imgarr],lablearr\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TxGw1_eBKQLu"
      },
      "outputs": [],
      "source": [
        "#프로젝트에 있는 모든 데이터폴터 불러오기\n",
        "#path + '\\\\sample_data\\\\sample_data\\\\*\\\\*.csv'\n",
        "data_files = glob(path + '\\\\sample_data\\\\sample_data\\\\*')\n",
        "#셔플\n",
        "random.shuffle(data_files)\n",
        "#앞에서 300번째까지 트레인셋으로\n",
        "trainfiles = data_files[:400]\n",
        "#나머지는 테스트셋으로\n",
        "testfiles = data_files[400:]\n",
        "\n",
        "# 데이터 컨트롤러\n",
        "dacon = DataController(csv_features,csv_feature_dict)\n",
        "# 배치화된 데이터셋 만들기\n",
        "# test셋용으로는 train = False로 하여 배치안생성하게됨\n",
        "x_train,y_train = dacon.getdata(trainfiles,260,9)\n",
        "x_test,y_test = dacon.getdata(testfiles,260,9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKGxfqdyKV8p"
      },
      "source": [
        "* 오토인코더 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eWWpQA7YlcAI"
      },
      "outputs": [],
      "source": [
        "class Eencoder(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Eencoder, self).__init__()\n",
        "        self.block1_layer1 = tf.keras.layers.Conv1D(9, 81, activation='relu',)#input_shape=input_shape[1:])\n",
        "        self.block1_layer2 = tf.keras.layers.Conv1D(18, 81, activation='relu',)#input_shape=input_shape[1:])\n",
        "        self.block1_layer3 = tf.keras.layers.Conv1D(36, 100, activation='relu',)#input_shape=input_shape[1:])\n",
        "         \n",
        "    def call(self, inputs):\n",
        "        #LSTM파트\n",
        "        lstm_x = self.block1_layer1(inputs)\n",
        "        lstm_x = tf.nn.relu(lstm_x)\n",
        "        lstm_x = self.block1_layer2(lstm_x)\n",
        "        lstm_x = tf.nn.relu(lstm_x)\n",
        "        lstm_x = self.block1_layer3(lstm_x)\n",
        "        lstm_x = tf.nn.relu(lstm_x)\n",
        "        \n",
        "        return lstm_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wFc4X54cl98v"
      },
      "outputs": [],
      "source": [
        "class Ddecoder(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Ddecoder, self).__init__()\n",
        "        self.block1_layer1 = tf.keras.layers.Conv1DTranspose(3, 81, activation='relu',)#input_shape=input_shape[1:])\n",
        "        self.block1_layer2 = tf.keras.layers.Conv1DTranspose(6, 81, activation='relu',)#input_shape=input_shape[1:])\n",
        "        self.block1_layer3 = tf.keras.layers.Conv1DTranspose(9, 100, activation='relu',)#input_shape=input_shape[1:])\n",
        "        \n",
        "         \n",
        "    def call(self, inputs):\n",
        "        #LSTM파트\n",
        "        x = self.block1_layer1(inputs)\n",
        "        \n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.block1_layer2(x)\n",
        "        \n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.block1_layer3(x)\n",
        "       \n",
        "        return x\n",
        "\n",
        "# Eencoder()(x_train[0][:2,:,:]).shape\n",
        "# Ddecoder()(Eencoder()(x_train[0][:2,:,:]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U6PCeaNLqpww"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(tf.keras.Model): \n",
        "  def __init__(self,): \n",
        "    super(Autoencoder, self).__init__() \n",
        "    self.encoder = Eencoder() \n",
        "    self.decoder = Ddecoder() \n",
        "  \n",
        "  def call(self, input): \n",
        "    code = self.encoder(input) \n",
        "    reconstructed = self.decoder(code) \n",
        "    return reconstructed\n",
        "\n",
        "def loss(model, original): \n",
        "  reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(model(original), original))) \n",
        "  return reconstruction_error\n",
        "\n",
        "def train(loss, model, opt, original): \n",
        "  with tf.GradientTape() as tape: \n",
        "    gradients = tape.gradient(loss(model, original), model.trainable_variables) \n",
        "    gradient_variables = zip(gradients, model.trainable_variables) \n",
        "    opt.apply_gradients(gradient_variables)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IJX0RI4k_2ca"
      },
      "outputs": [],
      "source": [
        "automodel = Autoencoder()\n",
        "opt = tf.optimizers.Adam()\n",
        "loss_fn = keras.losses.MeanSquaredError()\n",
        "automodel.compile(optimizer=opt, loss=loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KVNfPBDJEZJ",
        "outputId": "dd557254-3b6e-4d17-8e67-2fe50f255c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 1s 52ms/step - loss: 0.2471\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.1683\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.1344\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.1120\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.0923\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.0779\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.0669\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.0590\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.0535\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.0497\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.0467\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.0442\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.0424\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.0410\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.0398\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.0388\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0379\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0371\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.0364\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0358\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x263932edc70>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "automodel.fit(x_train[0], x_train[0], \n",
        "                 batch_size=100, \n",
        "                 epochs=20,\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIad-XctjZpT",
        "outputId": "c1ab6e75-1eb2-49cc-dc1f-cd5cfdb0eb16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testset에 오토인코더 손실함수 테스트:  tf.Tensor(0.036464117, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "y_pred = automodel(x_test[0])\n",
        "print(\"testset에 오토인코더 손실함수 테스트: \",loss_fn(x_test[0],y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ajf5v88Kf8o"
      },
      "source": [
        "* XGBoost 분류모델 ㄱㄱ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WaX_Met5Kwpb"
      },
      "outputs": [],
      "source": [
        "class preprmodel(keras.Model):\n",
        "    def __init__(self, imgmodel,autoencoder,name = None):\n",
        "        super(preprmodel, self).__init__()\n",
        "        self.imgmodel = imgmodel\n",
        "        self.autoencoder = autoencoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x1 = self.imgmodel(inputs[1])\n",
        "        x2 = self.autoencoder.encoder(inputs[0]).numpy().reshape(-1,36)\n",
        "\n",
        "\n",
        "        x = tf.concat([x1,x2],axis=1)\n",
        "        return(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ySD-3Xa1Kwpc"
      },
      "outputs": [],
      "source": [
        "model_RESNET50 = ResNet50(weights='imagenet')\n",
        "prepromodel = preprmodel(model_RESNET50,automodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "YlSjMBPcKwpc",
        "outputId": "c94e7b64-c3c7-4792-a486-a1427e8a7af4"
      },
      "outputs": [],
      "source": [
        "x_prime_train = prepromodel(x_train)\n",
        "x_prime_test = prepromodel(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UPj6SNJKwpc",
        "outputId": "8470cd27-a4b9-4076-8fcb-e5a30d7eeaca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(objective='multi:softprob', random_state=100)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "xgb = XGBClassifier(random_state=100)\n",
        "xgb.fit(x_prime_train,y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>preds</th>\n",
              "      <th>시설포도_정상</th>\n",
              "      <th>시설포도노균병_중기</th>\n",
              "      <th>시설포도탄저병_초기</th>\n",
              "      <th>일소피해_초기</th>\n",
              "      <th>파프리카_정상</th>\n",
              "      <th>파프리카흰가루병_중기</th>\n",
              "      <th>파프리카흰가루병_초기</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>시설포도_정상</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>시설포도노균병_중기</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>시설포도탄저병_중기</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>시설포도탄저병_초기</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>일소피해_말기</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>일소피해_초기</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>파프리카_정상</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>파프리카흰가루병_말기</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>파프리카흰가루병_중기</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>파프리카흰가루병_초기</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "preds        시설포도_정상  시설포도노균병_중기  시설포도탄저병_초기  일소피해_초기  파프리카_정상  파프리카흰가루병_중기  \\\n",
              "answer                                                                        \n",
              "시설포도_정상           33           0           0        0        0            0   \n",
              "시설포도노균병_중기         0           1           0        0        0            0   \n",
              "시설포도탄저병_중기         1           0           0        0        0            0   \n",
              "시설포도탄저병_초기         0           0           1        0        0            0   \n",
              "일소피해_말기            1           0           0        0        0            0   \n",
              "일소피해_초기            0           0           0        1        0            0   \n",
              "파프리카_정상            0           0           0        0       37            0   \n",
              "파프리카흰가루병_말기        2           0           0        0        0            0   \n",
              "파프리카흰가루병_중기        1           0           0        0        0            3   \n",
              "파프리카흰가루병_초기        1           0           0        0        0            5   \n",
              "\n",
              "preds        파프리카흰가루병_초기  \n",
              "answer                    \n",
              "시설포도_정상                0  \n",
              "시설포도노균병_중기             0  \n",
              "시설포도탄저병_중기             0  \n",
              "시설포도탄저병_초기             0  \n",
              "일소피해_말기                0  \n",
              "일소피해_초기                0  \n",
              "파프리카_정상                0  \n",
              "파프리카흰가루병_말기            2  \n",
              "파프리카흰가루병_중기            3  \n",
              "파프리카흰가루병_초기            7  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred=xgb.predict(x_prime_test)\n",
        "answer = np.array([label_description[label_decoder[int(val)]] for val in y_test])\n",
        "predss = np.array([label_description[label_decoder[int(val)]] for val in y_pred])\n",
        "\n",
        "new_crosstab = pd.crosstab(answer, predss, rownames=['answer'], colnames=['preds'])\n",
        "new_crosstab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[37  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  7  5  0  1  0  0  0  0  0]\n",
            " [ 0  3  3  0  1  0  0  0  0  0]\n",
            " [ 0  2  0  0  2  0  0  0  0  0]\n",
            " [ 0  0  0  0 33  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      1.000     1.000     1.000        37\n",
            "         1.0      0.583     0.538     0.560        13\n",
            "         2.0      0.375     0.429     0.400         7\n",
            "         3.0      0.000     0.000     0.000         4\n",
            "        19.0      0.846     1.000     0.917        33\n",
            "        20.0      1.000     1.000     1.000         1\n",
            "        21.0      0.000     0.000     0.000         1\n",
            "        24.0      1.000     1.000     1.000         1\n",
            "        26.0      1.000     1.000     1.000         1\n",
            "        28.0      0.000     0.000     0.000         1\n",
            "\n",
            "    accuracy                          0.838        99\n",
            "   macro avg      0.580     0.597     0.588        99\n",
            "weighted avg      0.789     0.838     0.811        99\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\rhqud\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Print the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_test, y_pred, digits=3))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model_001.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8865460eab3b8858828539624ef2f45d875655b94242e338bcb660acf08eeb38"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
